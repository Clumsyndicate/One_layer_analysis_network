{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnsonzhou/tf/.env/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "def quadratic(input):\n",
    "    return input ** 2\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple forward-pass model (Initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-4.55133677e-01 -7.19453156e-01]\n",
      " [-9.34290111e-01  7.87895381e-01]\n",
      " [-6.47171855e-01  2.35981882e-01]\n",
      " [-1.25431633e+00 -1.02161765e-01]\n",
      " [-2.94413000e-01 -2.28160545e-01]\n",
      " [-1.02677596e+00 -1.03598762e+00]\n",
      " [ 1.35793293e+00 -8.02385330e-01]\n",
      " [ 3.26944947e-01  3.97416294e-01]\n",
      " [-5.85688591e-01 -4.22685832e-01]\n",
      " [-1.43240333e+00  4.94211018e-01]\n",
      " [-1.05877113e+00  6.82642907e-02]\n",
      " [ 1.89540362e+00  2.38785923e-01]\n",
      " [ 1.13055277e+00 -1.95418608e+00]\n",
      " [-3.20964366e-01  1.75202167e+00]\n",
      " [-2.55721241e-01 -4.89555597e-01]\n",
      " [ 6.27795994e-01  5.68884313e-02]\n",
      " [ 2.82326341e-01 -1.96723390e+00]\n",
      " [ 6.54854059e-01  1.88779998e+00]\n",
      " [-1.09328657e-01  8.74767184e-01]\n",
      " [-1.84738427e-01 -1.21452056e-01]\n",
      " [ 6.09630086e-02 -1.26527250e+00]\n",
      " [-3.38760316e-01 -1.03736603e+00]\n",
      " [ 7.99575925e-01  2.85067052e-01]\n",
      " [ 1.93301886e-01  3.98400635e-01]\n",
      " [-2.32435346e+00 -7.75928974e-01]\n",
      " [ 2.04589939e+00  1.66039383e+00]\n",
      " [-9.06724453e-01  1.71466365e-01]\n",
      " [-3.93322974e-01  1.02365458e+00]\n",
      " [-1.15949929e+00  2.35671759e+00]\n",
      " [ 2.37793040e+00  1.44351733e+00]\n",
      " [-5.55931151e-01  2.42766351e-01]\n",
      " [-1.20842183e+00 -2.18447137e+00]\n",
      " [ 1.83661357e-01  4.49276268e-01]\n",
      " [ 6.04258716e-01  1.53196171e-01]\n",
      " [-1.25970602e+00  9.57852304e-01]\n",
      " [ 1.74104288e-01 -1.14210474e+00]\n",
      " [-2.56932735e-01  8.62860084e-01]\n",
      " [ 4.44162674e-02  4.74683136e-01]\n",
      " [ 1.04884946e+00 -3.44991565e-01]\n",
      " [-5.31071723e-01 -5.26058674e-01]\n",
      " [ 1.28855789e+00  2.42043376e-01]\n",
      " [-5.69642425e-01  1.35053682e+00]\n",
      " [-3.64303529e-01 -4.32934046e-01]\n",
      " [-1.31757891e+00  6.55293185e-03]\n",
      " [-7.37502575e-02 -1.42307699e-01]\n",
      " [-1.43308175e+00  8.95994782e-01]\n",
      " [ 2.98312843e-01 -1.24369872e+00]\n",
      " [ 1.06160200e+00 -5.88761210e-01]\n",
      " [-1.65027165e+00  5.59897348e-02]\n",
      " [-1.05940521e+00  1.02013767e+00]\n",
      " [ 2.92327881e-01  4.90260608e-02]\n",
      " [ 7.06601322e-01 -1.75019786e-01]\n",
      " [-8.28206182e-01  7.87308812e-02]\n",
      " [ 5.27940154e-01  1.64476025e+00]\n",
      " [-4.23160076e-01 -7.42534041e-01]\n",
      " [-5.81746399e-01 -1.35161734e+00]\n",
      " [ 2.16266203e+00  2.41269445e+00]\n",
      " [ 7.07285106e-01  1.03506315e+00]\n",
      " [ 1.38778031e-01  1.01535618e+00]\n",
      " [-2.54706889e-01 -1.74240768e+00]\n",
      " [ 9.56233442e-01 -2.09195182e-01]\n",
      " [-9.34148788e-01 -2.59577066e-01]\n",
      " [ 8.68605733e-01  1.62313974e+00]\n",
      " [ 9.96208549e-01 -1.82949170e-01]\n",
      " [-2.46899441e-01 -2.19828558e+00]\n",
      " [ 4.14778233e-01 -5.11124790e-01]\n",
      " [ 3.96002829e-01  3.29070628e-01]\n",
      " [-1.00768960e+00 -7.77877986e-01]\n",
      " [ 9.75721180e-01 -1.17501646e-01]\n",
      " [-1.56063661e-01 -7.51238763e-01]\n",
      " [-2.66342312e-01  1.58044100e+00]\n",
      " [ 5.02641141e-01  1.59110475e+00]\n",
      " [ 1.06363192e-01  7.46679902e-01]\n",
      " [-5.44715405e-01  8.84889960e-01]\n",
      " [ 4.97046083e-01 -1.92930377e+00]\n",
      " [-3.99778724e-01 -1.26990005e-01]\n",
      " [-6.00084186e-01  6.80468678e-01]\n",
      " [-8.13610077e-01  6.82218611e-01]\n",
      " [ 1.68913460e+00 -3.61528248e-01]\n",
      " [-2.24022612e-01  1.51846552e+00]\n",
      " [ 6.87870026e-01 -5.23546815e-01]\n",
      " [-5.88319600e-01  2.04010987e+00]\n",
      " [-5.04756570e-01 -1.91897705e-01]\n",
      " [ 3.11285377e-01 -1.28598109e-01]\n",
      " [-1.30131142e-03 -8.22203934e-01]\n",
      " [-2.96698004e-01 -4.27636802e-01]\n",
      " [-3.63015532e-02  1.45295680e-01]\n",
      " [-7.42275953e-01 -5.60876071e-01]\n",
      " [ 1.26253784e+00 -1.58548915e+00]\n",
      " [ 3.73480290e-01  2.78034806e-01]\n",
      " [-7.34280467e-01  4.61795926e-01]\n",
      " [-5.14201939e-01  2.68932581e-01]\n",
      " [ 2.37043881e+00  1.68629742e+00]\n",
      " [ 1.47299218e+00  1.47051167e+00]\n",
      " [-9.57278967e-01 -2.44531780e-02]\n",
      " [ 2.24130416e+00  1.40058637e-01]\n",
      " [-5.51046193e-01 -1.04257047e+00]\n",
      " [-1.66795516e+00 -1.47501135e+00]\n",
      " [-8.17167103e-01  3.23648125e-01]\n",
      " [-6.29456639e-02  1.00758672e+00]], shape=(100, 2), dtype=float32)\n",
      "Initial loss: 246.673\n",
      "Loss at step 000: 161.452\n",
      "Num =  1\n",
      "Final loss: 79.218\n",
      "2.6726482\n",
      "0.017274914\n",
      "Prediction loss: 103.203\n",
      "Initial loss: 196.552\n",
      "Loss at step 000: 245.342\n",
      "Num =  2\n",
      "Final loss: 79.218\n",
      "2.6967723\n",
      "-0.05706327\n",
      "Prediction loss: 121.474\n",
      "Initial loss: 178.225\n",
      "Loss at step 000: 134.986\n",
      "Num =  3\n",
      "Final loss: 79.218\n",
      "2.3974624\n",
      "-0.09762394\n",
      "Prediction loss: 41.044\n",
      "Initial loss: 122.084\n",
      "Loss at step 000: 170.531\n",
      "Num =  4\n",
      "Final loss: 79.218\n",
      "2.2416878\n",
      "-0.12862076\n",
      "Prediction loss: 137.015\n",
      "Initial loss: 155.286\n",
      "Loss at step 000: 164.937\n",
      "Num =  5\n",
      "Final loss: 79.218\n",
      "2.4032376\n",
      "0.13020378\n",
      "Prediction loss: 87.446\n",
      "Initial loss: 202.499\n",
      "Loss at step 000: 114.050\n",
      "Num =  6\n",
      "Final loss: 79.218\n",
      "2.4137068\n",
      "0.011966112\n",
      "Prediction loss: 34.125\n",
      "Initial loss: 120.264\n",
      "Loss at step 000: 104.038\n",
      "Num =  7\n",
      "Final loss: 79.218\n",
      "1.8726778\n",
      "0.036729816\n",
      "Prediction loss: 76.629\n",
      "Initial loss: 203.507\n",
      "Loss at step 000: 123.538\n",
      "Num =  8\n",
      "Final loss: 79.218\n",
      "2.3889248\n",
      "-0.008938279\n",
      "Prediction loss: 106.144\n",
      "Initial loss: 164.021\n",
      "Loss at step 000: 82.602\n",
      "Num =  9\n",
      "Final loss: 79.218\n",
      "1.899126\n",
      "-0.009373196\n",
      "Prediction loss: 125.556\n",
      "Initial loss: 148.907\n",
      "Loss at step 000: 115.514\n",
      "Num =  10\n",
      "Final loss: 79.218\n",
      "2.1107638\n",
      "-0.1146062\n",
      "Prediction loss: 6.960\n",
      "tf.Tensor(\n",
      "[[ 0.31464234  0.735031    0.04727202]\n",
      " [-0.7475171  -0.9207419  -0.03431574]\n",
      " [-1.2768921  -0.30029917  1.7732102 ]\n",
      " [-0.31647477 -1.7395034   0.15213248]\n",
      " [-0.02575223 -1.5111893   0.5865768 ]\n",
      " [ 0.64148813  1.4558125  -0.73886037]\n",
      " [ 0.45000875  1.0842459   0.57332265]\n",
      " [-0.8379226  -1.2741542   1.2478249 ]\n",
      " [ 0.6827864  -1.0179472   0.8642258 ]\n",
      " [-0.58589023 -0.11395092 -0.1720341 ]\n",
      " [-0.0433878  -1.2028748   0.752463  ]\n",
      " [-0.03826452 -0.73344135  2.1976764 ]\n",
      " [ 1.4097183  -0.8280586   1.2128942 ]\n",
      " [ 0.01786555 -0.1914755  -0.7297828 ]\n",
      " [-0.62253016  1.4877808   0.38912174]\n",
      " [-0.4481118   0.64714235 -0.5768476 ]\n",
      " [-1.1456989   1.7447578   1.2048036 ]\n",
      " [ 0.32638577  1.0658653   0.4101969 ]\n",
      " [ 0.14082628 -1.5339721  -0.05391599]\n",
      " [-0.80393356  0.6067305  -0.01619274]\n",
      " [-1.1135445   0.24173361 -1.2154754 ]\n",
      " [ 1.8410014   3.1034043   1.1316723 ]\n",
      " [-0.43879956 -0.15584804 -0.7948359 ]\n",
      " [-0.99857783 -0.34844238  0.32157576]\n",
      " [ 1.3824042   2.2238457   0.35765263]\n",
      " [ 0.457276    1.4725555  -0.4848523 ]\n",
      " [ 0.24587214 -0.5112778  -1.8067013 ]\n",
      " [ 0.9007445  -0.84938294  0.36603045]\n",
      " [-0.75022197  1.1303456   2.2692292 ]\n",
      " [-1.1615456   0.32221228  1.364832  ]\n",
      " [-0.65434     0.6293605  -1.7389388 ]\n",
      " [-0.06491344 -1.0250522  -0.3333889 ]\n",
      " [-1.4537865  -0.4707015  -0.25870252]\n",
      " [ 0.8913501  -1.782248    0.28326148]\n",
      " [-1.3083292  -0.6938149   0.4113443 ]\n",
      " [ 1.3533161  -1.7276387   0.8206481 ]\n",
      " [-1.0688813   0.18776266  0.0967288 ]\n",
      " [ 1.1770096   0.02605145 -0.5597577 ]\n",
      " [-0.9399683  -0.70296293  0.8454639 ]\n",
      " [-1.2801872  -0.32069308  0.5737618 ]\n",
      " [-0.78284615  0.04149941 -0.29380003]\n",
      " [ 1.842973   -0.36169642  0.19119726]\n",
      " [ 0.6214942   0.02609586  0.25330123]\n",
      " [ 1.1924803  -0.39398798  0.5412308 ]\n",
      " [-2.1625237   0.89440155 -1.3078512 ]\n",
      " [ 2.0381484  -0.366499   -1.2432582 ]\n",
      " [ 0.5976526   1.368073    0.95463556]\n",
      " [-1.8452836   1.3113354  -0.25888917]\n",
      " [ 0.03074619 -1.1406332   0.8015789 ]\n",
      " [ 0.8382257   0.3793949  -0.7246069 ]\n",
      " [ 1.0899692   0.61477226  1.3059262 ]\n",
      " [-1.9507629  -0.29362673  0.30172697]\n",
      " [ 0.78903085  1.092773   -0.1762504 ]\n",
      " [-0.58577716  0.36619934  2.1336198 ]\n",
      " [ 0.07504432 -0.25742635  2.22213   ]\n",
      " [ 1.6555998   1.3255639  -0.65855944]\n",
      " [ 0.76098335 -1.2976491   0.3476355 ]\n",
      " [ 1.4792572   1.0884975   1.7694355 ]\n",
      " [ 1.7955469  -1.1840754  -0.33839744]\n",
      " [ 0.03222017  0.01932937 -0.54685634]\n",
      " [ 1.6266322   1.0637423   0.06212586]\n",
      " [-2.1049817   1.1048516   2.8627384 ]\n",
      " [ 0.9656363   1.5492429  -1.263566  ]\n",
      " [-0.91151035  1.5630311   0.6591707 ]\n",
      " [-0.5391875   0.57219857  1.1778913 ]\n",
      " [ 1.7649556  -0.57803184  0.3314862 ]\n",
      " [-0.5411472   0.32430524  0.8955525 ]\n",
      " [ 0.7438748  -1.3992647  -0.83880687]\n",
      " [-1.4681988   0.911393    1.525759  ]\n",
      " [-1.088541   -1.2461934  -0.23202184]\n",
      " [-0.45295572 -0.96828616 -0.6488498 ]\n",
      " [-0.9156453  -1.1245908   0.02529957]\n",
      " [-0.2013245   0.8172872  -1.6090121 ]\n",
      " [ 0.924679    0.5764788  -0.5917559 ]\n",
      " [-1.6599109  -0.09302329 -0.9877752 ]\n",
      " [-0.47482976  0.55859756 -0.10913728]\n",
      " [-0.54037225 -0.6184985  -1.278728  ]\n",
      " [-1.1416637  -0.26472497  0.975782  ]\n",
      " [-0.5859001  -0.14580688 -0.58511734]\n",
      " [ 0.25303873 -0.58648014 -0.68037355]\n",
      " [ 1.1210517   0.5487208  -2.001597  ]\n",
      " [ 0.33728418  0.35475215  0.07521378]\n",
      " [-1.8756498  -2.6136265   2.0145566 ]\n",
      " [-0.5535622   0.35409987  0.98255825]\n",
      " [ 0.43154505  1.3051273  -2.0120976 ]\n",
      " [ 0.16124824  0.47953263 -0.6424511 ]\n",
      " [-0.22896579  1.8192334  -0.02774688]\n",
      " [-1.8742998  -0.00926929 -0.19565916]\n",
      " [-0.13405026  0.07535949  2.0122774 ]\n",
      " [ 0.97331125 -1.1830016   0.3777615 ]\n",
      " [ 1.4372642   0.538163    1.6279721 ]\n",
      " [ 2.1758025   0.18873172  0.99028605]\n",
      " [-0.59562916  0.42366442  1.2202526 ]\n",
      " [ 0.26820183 -0.07079636  0.5245091 ]\n",
      " [-0.06401871  1.2235478  -0.4050059 ]\n",
      " [-0.50593024 -1.9987612  -0.7292978 ]\n",
      " [-2.406085   -0.13450941  0.80931133]\n",
      " [ 0.14275846 -0.6057834  -0.1146741 ]\n",
      " [-0.3739372   1.3217697   2.1253295 ]\n",
      " [ 0.7108699  -1.3400142  -0.976582  ]], shape=(100, 3), dtype=float32)\n",
      "Initial loss: 164.538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 000: 158.989\n",
      "Num =  1\n",
      "Final loss: 113.346\n",
      "1.4761086\n",
      "-0.09395574\n",
      "Prediction loss: 438.647\n",
      "Initial loss: 134.396\n",
      "Loss at step 000: 216.567\n",
      "Num =  2\n",
      "Final loss: 113.346\n",
      "1.5218725\n",
      "-0.11048081\n",
      "Prediction loss: 349.820\n",
      "Initial loss: 113.273\n",
      "Loss at step 000: 156.312\n",
      "Num =  3\n",
      "Final loss: 113.346\n",
      "1.3833232\n",
      "-0.039135788\n",
      "Prediction loss: 128.700\n",
      "Initial loss: 225.022\n",
      "Loss at step 000: 285.055\n",
      "Num =  4\n",
      "Final loss: 113.346\n",
      "1.8770921\n",
      "-0.058931604\n",
      "Prediction loss: 291.325\n",
      "Initial loss: 231.947\n",
      "Loss at step 000: 152.613\n",
      "Num =  5\n",
      "Final loss: 113.346\n",
      "1.7236937\n",
      "0.060581435\n",
      "Prediction loss: 403.763\n",
      "Initial loss: 147.464\n",
      "Loss at step 000: 144.049\n",
      "Num =  6\n",
      "Final loss: 113.346\n",
      "1.372315\n",
      "0.0410562\n",
      "Prediction loss: 553.032\n",
      "Initial loss: 194.171\n",
      "Loss at step 000: 101.737\n",
      "Num =  7\n",
      "Final loss: 113.346\n",
      "1.4010189\n",
      "-0.07439646\n",
      "Prediction loss: 321.571\n",
      "Initial loss: 216.830\n",
      "Loss at step 000: 226.414\n",
      "Num =  8\n",
      "Final loss: 113.346\n",
      "1.8005987\n",
      "-0.24109869\n",
      "Prediction loss: 1543.061\n",
      "Initial loss: 129.674\n",
      "Loss at step 000: 214.277\n",
      "Num =  9\n",
      "Final loss: 113.346\n",
      "1.6543173\n",
      "-0.045004465\n",
      "Prediction loss: 1289.822\n",
      "Initial loss: 159.950\n",
      "Loss at step 000: 125.868\n",
      "Num =  10\n",
      "Final loss: 113.346\n",
      "1.5334495\n",
      "-0.0917089\n",
      "Prediction loss: 102.143\n",
      "tf.Tensor(\n",
      "[[-2.51267314e-01  1.50921595e+00 -4.18381542e-01  1.64746296e+00\n",
      "  -7.66054988e-01]\n",
      " [-9.32026327e-01 -4.07167189e-02  1.43163002e+00 -4.38336670e-01\n",
      "  -1.31436020e-01]\n",
      " [ 8.07255208e-02 -2.72834629e-01 -1.56238511e-01  5.12922764e-01\n",
      "  -1.32849407e+00]\n",
      " [-1.12990737e+00  2.96435684e-01 -1.18586087e+00 -2.24241495e+00\n",
      "   5.47099292e-01]\n",
      " [ 2.25412941e+00  1.21322298e+00 -3.35301161e-01  7.44612992e-01\n",
      "   6.32169962e-01]\n",
      " [ 6.52413145e-02 -2.30986640e-01 -9.65657651e-01 -4.87480387e-02\n",
      "  -7.94747412e-01]\n",
      " [-1.87340271e+00 -1.23850405e-01  4.14817512e-01 -4.87336546e-01\n",
      "  -9.74804223e-01]\n",
      " [ 3.36442024e-01  5.06285489e-01  5.06669462e-01 -4.40168440e-01\n",
      "   3.85340959e-01]\n",
      " [-1.15975618e+00  6.85939491e-01 -2.56216556e-01  2.11327657e-01\n",
      "  -1.69197232e-01]\n",
      " [ 7.23837137e-01  8.67298245e-01 -8.90587628e-01 -5.05138814e-01\n",
      "  -1.84908688e+00]\n",
      " [ 2.06436008e-01 -1.23192453e+00  1.55275762e+00 -4.06406581e-01\n",
      "   3.80414426e-02]\n",
      " [ 1.22570527e+00 -9.93644953e-01 -1.11767411e-01 -1.32259953e+00\n",
      "  -4.20142770e-01]\n",
      " [ 4.26723212e-01 -6.31602257e-02 -3.17034215e-01 -9.65854287e-01\n",
      "  -2.58254737e-01]\n",
      " [-1.69916415e+00  2.36854601e+00 -1.19108748e+00  3.26699577e-03\n",
      "  -2.35972598e-01]\n",
      " [-1.37581408e-01 -1.77086902e+00 -2.74421096e-01  1.88889158e+00\n",
      "  -9.23277259e-01]\n",
      " [ 5.93736708e-01  4.26621497e-01 -8.75403941e-01 -4.70444947e-01\n",
      "   1.11196506e+00]\n",
      " [-3.65744650e-01  8.82969081e-01  2.65458614e-01 -3.53221059e-01\n",
      "  -4.83956076e-02]\n",
      " [ 1.29688644e+00  6.69670939e-01 -1.62354022e-01 -1.07858765e+00\n",
      "  -1.30199218e+00]\n",
      " [-2.45266438e+00 -1.53510249e+00  6.17461562e-01  1.01092076e+00\n",
      "   5.26398778e-01]\n",
      " [-5.81162214e-01 -8.72639239e-01 -7.05685854e-01  9.49888527e-01\n",
      "   8.66634905e-01]\n",
      " [-8.70598376e-01 -1.16006799e-01  2.50227857e+00 -8.18170369e-01\n",
      "   1.20488405e+00]\n",
      " [ 6.37929976e-01  1.32466304e+00 -7.10730731e-01 -8.04090261e-01\n",
      "  -7.65161514e-01]\n",
      " [ 8.50565910e-01 -1.05266786e+00  5.23399003e-02  8.05470169e-01\n",
      "  -5.58010817e-01]\n",
      " [-3.96604419e-01  1.90583885e+00  9.38242614e-01  1.16746366e-01\n",
      "  -1.75826597e+00]\n",
      " [ 7.63583899e-01  1.33575368e+00 -1.43032634e+00  1.03986168e+00\n",
      "  -1.12413156e+00]\n",
      " [-1.14987206e+00 -1.17387938e+00 -6.00818932e-01  5.76463640e-01\n",
      "  -1.52329504e-01]\n",
      " [ 5.50624847e-01 -1.31305420e+00  3.86172146e-01 -5.40840387e-01\n",
      "  -3.80944133e-01]\n",
      " [ 8.98340166e-01  2.76282251e-01 -2.14318171e-01 -6.93894804e-01\n",
      "  -2.27792263e+00]\n",
      " [-1.83560455e+00 -2.03024805e-01  2.01054239e+00 -4.64517832e-01\n",
      "  -1.59946725e-01]\n",
      " [-1.17647922e+00  3.09124917e-01  1.44726086e+00 -7.95278728e-01\n",
      "   1.19227648e+00]\n",
      " [-7.82095566e-02 -1.55896950e+00  1.81197751e+00 -5.49325347e-01\n",
      "   3.74784440e-01]\n",
      " [ 4.80130672e-01 -6.49034202e-01  9.56353188e-01 -2.76126284e-02\n",
      "   1.05167961e+00]\n",
      " [ 8.15072596e-01  7.17550993e-01 -4.66661781e-01  1.54898793e-01\n",
      "  -2.29896948e-01]\n",
      " [-3.37479353e-01 -5.78870654e-01  6.71562016e-01 -1.25512600e+00\n",
      "  -1.57778665e-01]\n",
      " [-9.30824578e-01  1.27208316e+00 -6.65304303e-01 -9.20653999e-01\n",
      "  -9.19267759e-02]\n",
      " [ 1.40202606e+00 -2.15508580e+00  3.30757052e-02  8.99363577e-01\n",
      "   4.77328300e-01]\n",
      " [ 1.54630661e-01  1.15492928e+00  7.78467298e-01 -1.45103598e+00\n",
      "  -5.60876667e-01]\n",
      " [ 9.28449109e-02 -1.32718503e+00 -2.41532969e+00 -7.45841265e-01\n",
      "  -9.92532849e-01]\n",
      " [-9.62188959e-01  2.06927490e+00 -4.93296891e-01 -3.75440627e-01\n",
      "  -1.72151303e+00]\n",
      " [-2.33033538e-01  5.27545869e-01  4.98471111e-01  7.53884196e-01\n",
      "   1.83881342e+00]\n",
      " [ 6.71642780e-01 -5.05049713e-02  9.74366367e-01 -1.09591389e+00\n",
      "  -9.79578197e-01]\n",
      " [-7.88909554e-01 -2.02141583e-01  6.14473999e-01 -1.32718408e+00\n",
      "   8.55555981e-02]\n",
      " [-5.01522958e-01  2.01604509e+00 -1.76619542e+00  3.28408599e-01\n",
      "   1.43921807e-01]\n",
      " [ 2.09878683e+00 -4.51902509e-01  1.35873723e+00  2.02726078e+00\n",
      "  -4.32135642e-01]\n",
      " [ 2.30345845e+00 -4.29679155e-01 -6.36620462e-01  4.52874988e-01\n",
      "   1.26102722e+00]\n",
      " [-9.04849529e-01  2.01111102e+00  5.98403394e-01 -2.00235114e-01\n",
      "  -4.13973331e-01]\n",
      " [-1.30850613e+00  1.23293066e+00  6.02079093e-01 -1.94253123e+00\n",
      "   4.06913012e-01]\n",
      " [ 2.20787346e-01 -8.49970356e-02  1.46352053e-01  1.66732955e+00\n",
      "   5.34442253e-02]\n",
      " [ 3.00444037e-01 -1.08723938e+00 -9.70378667e-02  7.81548917e-01\n",
      "   9.70933259e-01]\n",
      " [-6.22646213e-01  3.16595495e-01  4.65836406e-01  9.31085289e-01\n",
      "  -1.82653740e-01]\n",
      " [ 1.30646980e+00 -7.09629893e-01 -1.77917089e-02 -1.45281672e+00\n",
      "   2.23072028e+00]\n",
      " [-2.34476066e+00 -5.45639753e-01  5.91498017e-01 -7.96684861e-01\n",
      "   6.14874065e-02]\n",
      " [ 3.79016697e-01 -4.28709596e-01 -6.65377557e-01 -2.14821768e+00\n",
      "  -1.31515920e+00]\n",
      " [-2.42759213e-02 -1.32591829e-01 -2.23822498e+00  1.20271727e-01\n",
      "   7.81413198e-01]\n",
      " [ 1.17902553e+00  8.27927068e-02 -6.09173119e-01 -3.09403372e+00\n",
      "   3.43621045e-01]\n",
      " [-2.69862801e-01  1.57756448e+00 -1.52660251e-01  9.95177329e-01\n",
      "   1.79280984e+00]\n",
      " [-1.06677292e-02  1.49286115e+00  6.98077857e-01  1.29691660e-01\n",
      "   3.47213268e+00]\n",
      " [-1.01918983e+00  4.16201472e-01 -1.19963169e+00  6.39852166e-01\n",
      "  -6.06290936e-01]\n",
      " [-8.35159957e-01  8.01257193e-02  1.74900234e+00 -1.33679807e+00\n",
      "  -1.76845506e-01]\n",
      " [-2.89234072e-01 -9.03231204e-01  1.22003102e+00 -4.70257044e-01\n",
      "   5.93812823e-01]\n",
      " [ 2.72539943e-01 -9.94440973e-01 -1.06984961e+00  1.44133341e+00\n",
      "   5.25498331e-01]\n",
      " [ 1.17576480e+00 -1.35769975e+00 -1.60171044e+00 -5.46416566e-02\n",
      "   1.43499710e-02]\n",
      " [-5.57560086e-01 -9.59274650e-01  5.42418838e-01  2.70527452e-01\n",
      "   8.74384224e-01]\n",
      " [ 1.56017768e+00 -5.38468480e-01 -7.21056163e-01  2.48811394e-01\n",
      "   1.21893883e+00]\n",
      " [-1.31756347e-03  2.60517049e+00  1.26440144e+00 -1.74258399e+00\n",
      "  -2.50951201e-01]\n",
      " [-8.48148525e-01 -1.13341486e+00 -5.81985116e-01  9.09591675e-01\n",
      "  -8.35384607e-01]\n",
      " [-6.64525986e-01  7.03817606e-01 -8.97127628e-01 -1.21312089e-01\n",
      "  -7.36234307e-01]\n",
      " [-6.23354614e-01  2.34955270e-03  1.55290008e+00  1.42582981e-02\n",
      "   9.74990129e-01]\n",
      " [ 6.85151815e-01 -3.05466473e-01  1.02570653e-02  1.02229428e+00\n",
      "   1.17207861e+00]\n",
      " [-8.29643786e-01  1.53210664e+00 -1.83240678e-02  1.54953074e+00\n",
      "   1.15788686e+00]\n",
      " [-7.94542253e-01  3.56399328e-01  1.24520220e-01 -9.60631847e-01\n",
      "   7.10734546e-01]\n",
      " [ 1.03983200e+00 -1.05705708e-01 -2.53477621e+00 -3.84638906e-01\n",
      "  -1.47129929e+00]\n",
      " [ 5.59660554e-01  1.66932106e+00  1.35369015e+00 -8.11352730e-01\n",
      "   1.68476355e+00]\n",
      " [-4.49391603e-01 -1.45527152e-02 -4.97963607e-01 -7.99629033e-01\n",
      "  -3.20564061e-01]\n",
      " [-4.45656568e-01 -8.17047477e-01 -2.40456533e+00 -1.15647697e+00\n",
      "  -1.05169289e-01]\n",
      " [ 6.36791408e-01 -5.58570206e-01 -6.39201641e-01 -3.27345937e-01\n",
      "   1.17110245e-01]\n",
      " [-1.86254418e+00  6.97913527e-01  2.52215505e+00 -1.27856886e+00\n",
      "  -4.49497283e-01]\n",
      " [-2.01695466e+00  4.42257553e-01  2.26847112e-01 -1.25280544e-01\n",
      "  -2.05744791e+00]\n",
      " [-1.52041841e+00  1.49102712e+00 -2.41829529e-01 -5.87738931e-01\n",
      "   2.33516112e-01]\n",
      " [-1.07199989e-01  5.22124052e-01  6.00651622e-01  2.96210349e-01\n",
      "   1.41897762e+00]\n",
      " [-8.03021789e-01  7.59975836e-02 -6.59365237e-01  1.24163663e+00\n",
      "   1.14940619e+00]\n",
      " [-5.45940876e-01  6.47972822e-01 -1.27381861e-01  3.23247492e-01\n",
      "  -7.89107621e-01]\n",
      " [ 7.36218989e-02 -6.78006351e-01  2.19809818e+00 -4.04930115e-01\n",
      "  -9.42286476e-02]\n",
      " [-8.46187711e-01  6.77430406e-02  1.39685202e+00 -2.21030608e-01\n",
      "  -3.34150344e-03]\n",
      " [-4.88824807e-02 -2.16903295e-02  2.84068298e+00  1.51843935e-01\n",
      "  -3.67563039e-01]\n",
      " [-1.56670296e+00  3.07954699e-01  2.50452667e-01 -4.48973715e-01\n",
      "  -1.72231185e+00]\n",
      " [-1.45970309e+00 -9.65064764e-01  1.40845084e+00 -2.58524716e-01\n",
      "   1.30410969e+00]\n",
      " [ 1.36362100e+00  1.64562249e+00  5.90105057e-01  9.90798056e-01\n",
      "  -9.69819069e-01]\n",
      " [-1.36815381e+00 -1.94105536e-01 -8.32592070e-01 -1.23428583e+00\n",
      "   2.32981658e+00]\n",
      " [-2.48607230e+00 -1.48310196e+00 -7.69274473e-01  1.01175988e+00\n",
      "  -4.17790711e-01]\n",
      " [-1.06955862e+00  2.52270889e+00  4.28434223e-01  1.35990131e+00\n",
      "  -4.33156312e-01]\n",
      " [ 6.78472638e-01 -5.39924622e-01 -3.71475369e-01 -3.23380232e-01\n",
      "   1.27952206e+00]\n",
      " [-1.53667855e+00 -6.74951255e-01  1.37712955e+00  1.72834551e+00\n",
      "   7.50658959e-02]\n",
      " [ 1.01365462e-01 -2.58983046e-01 -2.07397056e+00  2.60871410e-01\n",
      "  -5.54382466e-02]\n",
      " [ 8.96194160e-01 -5.80989063e-01  1.20247209e+00  1.92613566e+00\n",
      "   1.21743953e+00]\n",
      " [-4.04996052e-02 -1.62819743e+00 -4.60504651e-01  1.21611214e+00\n",
      "  -3.51861298e-01]\n",
      " [ 1.75295591e-01  2.54105139e+00 -1.81596935e+00 -3.65251631e-01\n",
      "  -1.90031242e+00]\n",
      " [-1.05366957e+00 -8.49548101e-01 -1.44109941e+00  9.14932966e-01\n",
      "  -2.20879245e+00]\n",
      " [ 4.00523022e-02 -1.19411099e+00 -2.05806240e-01  2.31665063e+00\n",
      "   1.44529390e+00]\n",
      " [-1.06569231e+00  2.60623837e+00 -1.22846198e+00  1.32548600e-01\n",
      "  -2.85931211e-02]], shape=(100, 5), dtype=float32)\n",
      "Initial loss: 166.796\n",
      "Loss at step 000: 90.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num =  1\n",
      "Final loss: 84.922\n",
      "1.170472\n",
      "-0.037949238\n",
      "Prediction loss: 57.618\n",
      "Initial loss: 137.718\n",
      "Loss at step 000: 92.695\n",
      "Num =  2\n",
      "Final loss: 85.735\n",
      "1.0711905\n",
      "0.041093584\n",
      "Prediction loss: 247.859\n",
      "Initial loss: 201.922\n",
      "Loss at step 000: 86.846\n",
      "Loss at step 020: 82.817\n",
      "Num =  3\n",
      "Final loss: 82.809\n",
      "1.1356851\n",
      "0.025664603\n",
      "Prediction loss: 89.014\n",
      "Initial loss: 148.375\n",
      "Loss at step 000: 84.428\n",
      "Num =  4\n",
      "Final loss: 88.304\n",
      "1.0738174\n",
      "0.054790985\n",
      "Prediction loss: 121.148\n",
      "Initial loss: 122.059\n",
      "Loss at step 000: 81.793\n",
      "Loss at step 020: 85.920\n",
      "Num =  5\n",
      "Final loss: 85.904\n",
      "1.0847675\n",
      "-0.025111075\n",
      "Prediction loss: 69.459\n",
      "Initial loss: 184.040\n",
      "Loss at step 000: 92.640\n",
      "Loss at step 020: 78.922\n",
      "Num =  6\n",
      "Final loss: 85.734\n",
      "1.1704826\n",
      "0.040219005\n",
      "Prediction loss: 54.685\n",
      "Initial loss: 173.015\n",
      "Loss at step 000: 95.272\n",
      "Num =  7\n",
      "Final loss: 84.395\n",
      "1.1805727\n",
      "0.08126483\n",
      "Prediction loss: 118.516\n",
      "Initial loss: 191.085\n",
      "Loss at step 000: 100.584\n",
      "Num =  8\n",
      "Final loss: 91.363\n",
      "1.1526821\n",
      "0.08353875\n",
      "Prediction loss: 116.172\n",
      "Initial loss: 141.613\n",
      "Loss at step 000: 76.899\n",
      "Loss at step 020: 75.531\n",
      "Loss at step 040: 85.295\n",
      "Num =  9\n",
      "Final loss: 89.853\n",
      "1.0401764\n",
      "0.0015251753\n",
      "Prediction loss: 248.126\n",
      "Initial loss: 206.048\n",
      "Loss at step 000: 114.172\n",
      "Num =  10\n",
      "Final loss: 84.846\n",
      "1.1751742\n",
      "0.064615525\n",
      "Prediction loss: 50.182\n",
      "tf.Tensor(\n",
      "[[-0.45839533  0.5187867  -0.82472503  0.39607352  1.0033029   1.2261385\n",
      "  -0.60149187]\n",
      " [-0.23005551 -1.2980686  -0.07787513  1.8619225   0.6483363  -0.31569096\n",
      "  -1.2123641 ]\n",
      " [ 0.16952036 -2.0264096  -0.22566849  0.6782624   0.24948771 -1.4308659\n",
      "   0.50808233]\n",
      " [-0.22559366 -0.76662433 -0.36353177  0.27122194  0.7797334  -2.1907108\n",
      "   0.8865953 ]\n",
      " [ 0.63249177  1.3257989  -0.48574445  0.01810632  0.24509047 -0.44545949\n",
      "   0.6664077 ]\n",
      " [-1.4089295   0.09897121 -0.08426356  0.20000991 -0.73648316  1.7031413\n",
      "  -0.03377798]\n",
      " [ 0.8272807   0.5681545   2.2859988  -2.0551503  -0.77752995 -0.51762646\n",
      "   0.4539892 ]\n",
      " [ 0.3019554   0.5163141  -2.274495    0.46377856  0.70702654 -0.88575935\n",
      "  -0.4504742 ]\n",
      " [ 0.02503348 -0.8433361  -0.7152271  -0.34932375 -0.3947208  -0.09382602\n",
      "   1.8977    ]\n",
      " [ 1.1208915  -0.5564388  -1.9844462   0.27581897  0.27379563  1.2085036\n",
      "  -0.6102043 ]\n",
      " [-1.3171577  -0.5173827  -0.32288462 -2.542936    0.738996   -0.07209402\n",
      "   0.09520587]\n",
      " [ 0.94144183 -0.23232442  1.3777975   0.6720217  -0.5401127  -1.7522837\n",
      "  -0.1317704 ]\n",
      " [ 0.05201286 -0.17373626 -1.2031295   0.7267278   0.6757461  -1.1959293\n",
      "  -0.928811  ]\n",
      " [ 0.7203275  -0.81909937  0.15691519  0.45720688  0.80722266 -0.47849107\n",
      "  -0.09940062]\n",
      " [ 0.07353399  0.03403116 -0.34474495 -0.2547417  -0.04393864  0.84474194\n",
      "  -2.4160752 ]\n",
      " [ 1.079014   -1.42966     0.27698717  1.2134187   2.4383028   1.1018414\n",
      "   1.8842088 ]\n",
      " [ 0.598156   -1.0257598  -1.3354264  -0.7078788   1.1108128   0.37227026\n",
      "  -0.79195166]\n",
      " [-0.6419622   1.0373396  -1.1019189  -1.0382154  -0.47463503 -1.1625772\n",
      "  -0.70495796]\n",
      " [ 0.33418638  0.05930275  0.9187333   0.25307906  1.6194524  -1.5672815\n",
      "  -0.77519894]\n",
      " [ 0.94051623 -1.4500163   1.0534452  -0.01535945  0.99006754  0.5280394\n",
      "  -1.2440965 ]\n",
      " [-0.25002122  0.874659   -0.61795163 -0.44293532 -1.3044819   0.24712573\n",
      "  -0.78648627]\n",
      " [ 0.87814987 -0.3802571   0.41356504 -1.2993524  -1.5179341   0.37631246\n",
      "   0.00533661]\n",
      " [ 0.12883928 -1.3452533  -1.516838   -0.376241   -2.213037    0.06351974\n",
      "   0.73895264]\n",
      " [ 0.97801983 -0.5308194  -0.11554721  0.1361853  -0.09975182 -1.5068051\n",
      "  -0.07078262]\n",
      " [ 0.3327731   0.2833259  -0.35317796 -0.49638343  1.1050813   0.9582906\n",
      "   1.0149536 ]\n",
      " [-0.7621482  -0.73774606  0.7932408  -0.70531005 -0.2612383   0.705062\n",
      "   1.3908669 ]\n",
      " [ 1.464541   -0.35382563  0.60878646 -0.64530206 -1.3922364  -0.38581374\n",
      "  -1.1662694 ]\n",
      " [ 0.99711066 -2.0992687  -1.0149583   1.1813319  -0.7460288  -2.3517048\n",
      "  -0.08938446]\n",
      " [-2.0542254   0.960133   -0.36783236 -2.6410348  -0.7208702  -1.1679347\n",
      "   0.5503812 ]\n",
      " [-0.28404102 -1.0737735   0.07476821 -1.7953305  -1.3454753  -1.1395525\n",
      "   0.20215826]\n",
      " [-0.27208012 -0.3392277   0.72879505 -0.8378341  -0.03756874 -0.901739\n",
      "  -1.3495728 ]\n",
      " [ 1.5802501   1.246485    1.7897667  -0.4541845  -0.4611951  -1.3446652\n",
      "  -0.6154316 ]\n",
      " [ 1.4154601  -0.42417178  0.8098447  -0.231286    0.36510694 -1.5146157\n",
      "   2.4091017 ]\n",
      " [ 0.17983608 -1.9411978   0.20240526  0.46649298  0.8856909  -1.7369707\n",
      "   1.3474435 ]\n",
      " [ 1.1918073  -0.97237664  2.6851554   0.77795243  0.85222644  0.54056036\n",
      "   0.01302005]\n",
      " [ 0.35836384  0.2146338  -0.90201294  2.420521   -1.0997151   0.40548488\n",
      "   0.14350702]\n",
      " [ 0.40410197  0.6223428  -0.35935524 -0.54046875 -0.00516063 -0.9985104\n",
      "   0.4952598 ]\n",
      " [ 0.785576    0.08208644 -1.0048056   1.62366     0.47628555 -0.99041003\n",
      "   2.0172355 ]\n",
      " [ 0.01783183 -0.6477707  -1.009187    0.9945535  -0.89673835 -0.43760335\n",
      "   0.75656074]\n",
      " [-0.35488248  0.08924036  0.37169057 -0.23731871  0.5329249  -0.29365215\n",
      "   0.8926669 ]\n",
      " [-0.09145451  0.07050584  1.1277814  -0.32175484  0.19349222  0.37622055\n",
      "   2.6651938 ]\n",
      " [ 2.0388932  -1.2987598   0.0923686   0.3035429   0.6497237   2.0653098\n",
      "   0.5238203 ]\n",
      " [-1.3038901  -0.25784722 -0.6602874  -0.27734944  1.4016569   0.55079705\n",
      "  -0.94688654]\n",
      " [-0.25805113 -0.24541509  1.4494618  -0.05707953 -1.2133166   1.1413493\n",
      "  -0.55030185]\n",
      " [ 0.615665   -0.33841684  0.4338759   1.0666947   0.34424382 -0.6326932\n",
      "   2.2421277 ]\n",
      " [ 1.2403764  -0.77070314  1.6576346   0.29796937  0.51609504 -0.60854554\n",
      "   0.77698433]\n",
      " [ 0.08883594 -0.91105354  0.7552698   1.0563216  -0.61984026 -1.5497347\n",
      "  -1.8391391 ]\n",
      " [-0.7023872  -0.24105884 -0.70245236  0.06589709  1.9966972   0.50238734\n",
      "   0.8982484 ]\n",
      " [ 0.44503334  0.15969965 -1.0847151  -2.473944   -0.41920507 -0.04896568\n",
      "   1.2536466 ]\n",
      " [-1.061772    1.251921   -1.7750343  -1.2407032   0.66023576 -0.6356433\n",
      "  -0.02705298]\n",
      " [ 0.6583105   3.1136312  -1.0398779  -0.5900317  -0.7653208   0.23501375\n",
      "   0.9867106 ]\n",
      " [ 0.07181815  1.8226724   1.0460812  -0.11116415  0.30539855 -1.7545507\n",
      "  -0.76420105]\n",
      " [-2.0106294   0.70414305 -0.40078214 -0.06296354  0.08779926 -2.9512384\n",
      "  -0.80370265]\n",
      " [ 0.46792588 -1.8306514   0.35172856 -1.6134455  -0.8231447   2.9582806\n",
      "  -0.9228038 ]\n",
      " [-0.98736125 -0.45743287  0.50806075 -0.12291727 -0.91890854  0.30272776\n",
      "  -0.13821344]\n",
      " [ 0.844486    1.6529472  -0.998019    0.6229781  -1.6696248  -0.15085034\n",
      "   0.42605886]\n",
      " [-0.33543894 -1.2025911   0.69264185 -0.6044692   0.17036021  1.4310127\n",
      "  -0.48512372]\n",
      " [ 0.41734114 -1.2025411   1.7186232   0.42033774  0.55778396  0.60045856\n",
      "  -0.29492098]\n",
      " [ 0.08060363 -1.0352741  -1.09624    -2.490444    0.096066    0.8006878\n",
      "   2.060749  ]\n",
      " [ 0.31282973 -0.6948327  -1.336832   -0.30847666 -0.3580492  -0.56841266\n",
      "  -0.34532633]\n",
      " [-1.537465   -1.4846607  -1.217675   -0.49422082 -0.08053852 -0.6238117\n",
      "   1.0600685 ]\n",
      " [ 0.6773918  -0.35892093 -1.1561195  -0.6367334   0.43388012  0.83118105\n",
      "  -0.9670308 ]\n",
      " [ 0.60578096 -0.21712509 -0.47453994  1.7713703  -0.39442283  0.5831521\n",
      "   0.66765565]\n",
      " [-1.1548581   0.22290327 -0.85559905  1.9461664   1.9282091  -1.1892377\n",
      "   1.9346864 ]\n",
      " [ 0.3862861   2.4720654  -1.1928618   0.29990548  0.6111574   0.8876509\n",
      "  -1.0337162 ]\n",
      " [-0.57963526 -0.38063812 -1.0961263  -0.8213053  -1.19579    -0.26394948\n",
      "  -0.1271356 ]\n",
      " [ 0.5544093   0.7344897   1.7107489   2.4375684   2.33963    -0.25846854\n",
      "   0.8984562 ]\n",
      " [-1.7682272   0.5592407   0.49877465  0.6008055  -1.5239254  -0.21022646\n",
      "  -0.749688  ]\n",
      " [-0.06623958 -1.4617397   0.01133031  1.0712749  -1.6644157  -0.58455044\n",
      "  -0.66672987]\n",
      " [ 0.59064144  0.13245496 -0.6914411   0.39382583  0.16910754 -0.41474542\n",
      "   0.21171094]\n",
      " [ 0.87837416  0.31141967  0.5562348  -0.18072361  0.7605427   2.816151\n",
      "   0.64112085]\n",
      " [ 0.97455096 -0.9687548   0.12242261 -1.9901898  -0.04678748  0.44881925\n",
      "   0.8910657 ]\n",
      " [-1.0052621  -0.18393333  0.5100898  -0.25833407  0.81145424 -1.347934\n",
      "  -1.1627449 ]\n",
      " [-1.8209505   0.7443523  -0.22016956 -0.5171585  -1.227097    0.16506952\n",
      "  -0.10658045]\n",
      " [ 0.5374318  -1.6565331   0.2644909   0.30026796 -0.02074883  0.78712595\n",
      "  -0.35478392]\n",
      " [-0.74649185  0.27790886  0.89723617  0.80231655  0.60933644 -0.5375801\n",
      "  -0.8949495 ]\n",
      " [ 0.22619201  1.3022044   1.6106216   0.13743094 -0.54533947 -0.69560057\n",
      "  -1.0686517 ]\n",
      " [ 0.12338358 -0.9215571  -0.59695363 -1.2202266  -1.5453193  -1.162705\n",
      "  -3.0777838 ]\n",
      " [-0.082159   -0.8677017   0.20167416 -0.45844474  0.6448402   0.70900124\n",
      "   0.33337602]\n",
      " [ 0.6129772  -0.4486491   0.78168374 -0.26215312  0.3723415   1.5255873\n",
      "   1.3729067 ]\n",
      " [-0.78119165  0.54689515  0.21316446 -1.4338574  -0.0500637   0.49357292\n",
      "   1.1837295 ]\n",
      " [ 0.35632184  0.9165623  -0.6447696  -1.0853028  -1.6316681   0.3287924\n",
      "  -0.61739236]\n",
      " [ 1.4161335  -0.8731331  -2.124251    0.18780363 -0.8803118  -1.2094339\n",
      "   0.02126423]\n",
      " [-0.11243076 -0.5030774   0.81430095  1.0664741   1.163425    0.89783156\n",
      "   0.6912043 ]\n",
      " [ 0.02590826  2.2224672   0.57721776 -0.45009252  0.7638069   1.0449888\n",
      "  -0.2407458 ]\n",
      " [-0.03634973  0.33437675  0.39980748  2.6397314   0.30522877 -1.2505988\n",
      "  -0.61282426]\n",
      " [ 0.01531253  0.10011634  1.2768741   1.910116    0.14964208  0.73834014\n",
      "   0.42120346]\n",
      " [-0.250173   -0.98693204 -1.1663425  -1.1673572   0.9903461  -0.05827936\n",
      "  -1.6657993 ]\n",
      " [-0.5973711   1.2715582   1.1004326  -2.1192203   1.1688167   0.40061077\n",
      "   0.6303738 ]\n",
      " [-1.4036657   0.08497737 -1.0885129   1.3328297   1.134497    1.1063035\n",
      "  -0.35450608]\n",
      " [ 0.9669037   1.1045179  -0.02600901  1.2717794   1.6044531   0.69313836\n",
      "   0.21292493]\n",
      " [ 0.6095349  -0.49428615 -1.9171346  -0.46071157  0.24814174  0.5026971\n",
      "  -0.46426252]\n",
      " [ 0.31443954  1.2509394  -0.91402876 -0.23630764 -0.8464279  -1.8062904\n",
      "   0.6297803 ]\n",
      " [-0.4141914  -1.5028427  -1.443287   -1.2452142  -0.925765   -0.17426203\n",
      "  -1.6981401 ]\n",
      " [ 0.78656507 -1.9260802  -0.70927906 -0.7611737   0.2680938  -0.9402839\n",
      "  -0.13614608]\n",
      " [ 0.0826455  -1.3801425  -0.2620366  -0.02309349  0.62953156  0.928992\n",
      "  -0.3197258 ]\n",
      " [-1.3702766   0.37313762  1.4144789  -0.51634073  0.39977318 -0.322435\n",
      "  -1.3880513 ]\n",
      " [ 0.8505111   0.08060712  0.95159924  0.7701156   0.9017981  -0.7318729\n",
      "  -0.36719516]\n",
      " [ 0.44532838 -0.09329372  0.5863444  -0.84570515 -1.1043098   1.1189907\n",
      "  -0.71369755]\n",
      " [-1.0990009  -1.1177148   0.13602078  1.356624    0.42302266  1.5890878\n",
      "  -0.13552287]], shape=(100, 7), dtype=float32)\n",
      "Initial loss: 133.033\n",
      "Loss at step 000: 81.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num =  1\n",
      "Final loss: 69.250\n",
      "1.0171134\n",
      "0.013413547\n",
      "Prediction loss: 204.402\n",
      "Initial loss: 153.230\n",
      "Loss at step 000: 89.676\n",
      "Num =  2\n",
      "Final loss: 80.992\n",
      "1.0504994\n",
      "0.10587353\n",
      "Prediction loss: 234.609\n",
      "Initial loss: 127.118\n",
      "Loss at step 000: 88.232\n",
      "Num =  3\n",
      "Final loss: 84.243\n",
      "1.0362647\n",
      "-0.005597097\n",
      "Prediction loss: 325.473\n",
      "Initial loss: 132.943\n",
      "Loss at step 000: 94.598\n",
      "Num =  4\n",
      "Final loss: 86.817\n",
      "0.9584284\n",
      "0.050231732\n",
      "Prediction loss: 221.221\n",
      "Initial loss: 182.279\n",
      "Loss at step 000: 86.681\n",
      "Loss at step 020: 73.085\n",
      "Num =  5\n",
      "Final loss: 73.059\n",
      "1.0266356\n",
      "0.035667244\n",
      "Prediction loss: 186.052\n",
      "Initial loss: 154.940\n",
      "Loss at step 000: 86.534\n",
      "Num =  6\n",
      "Final loss: 76.808\n",
      "1.027097\n",
      "-0.016974695\n",
      "Prediction loss: 203.786\n",
      "Initial loss: 172.318\n",
      "Loss at step 000: 91.197\n",
      "Num =  7\n",
      "Final loss: 87.361\n",
      "1.0180569\n",
      "-0.0103260325\n",
      "Prediction loss: 155.526\n",
      "Initial loss: 150.028\n",
      "Loss at step 000: 93.441\n",
      "Loss at step 020: 83.700\n",
      "Num =  8\n",
      "Final loss: 83.697\n",
      "1.048565\n",
      "0.0017686485\n",
      "Prediction loss: 166.360\n",
      "Initial loss: 142.092\n",
      "Loss at step 000: 81.499\n",
      "Num =  9\n",
      "Final loss: 76.090\n",
      "1.0027783\n",
      "0.06397575\n",
      "Prediction loss: 194.366\n",
      "Initial loss: 151.051\n",
      "Loss at step 000: 87.759\n",
      "Num =  10\n",
      "Final loss: 80.307\n",
      "1.0470407\n",
      "-0.03072781\n",
      "Prediction loss: 298.677\n",
      "tf.Tensor(\n",
      "[[ 7.64226258e-01  4.01153602e-03 -5.99057436e-01  8.29835534e-01\n",
      "  -7.11127996e-01  1.28545094e+00 -1.46160412e+00  1.01638876e-01\n",
      "   1.30024350e+00  6.79979622e-01]\n",
      " [ 2.48987749e-01 -2.59776354e-01 -2.67027229e-01  5.78244567e-01\n",
      "   1.11908329e+00  2.29875898e+00 -6.16259158e-01 -8.06971610e-01\n",
      "  -1.83341825e+00  6.93147004e-01]\n",
      " [-4.72358502e-02 -9.48859692e-01  4.70383465e-01 -1.37973893e+00\n",
      "  -6.12511754e-01 -1.59468696e-01 -7.85326958e-02  4.39288884e-01\n",
      "   6.50797710e-02  9.62085366e-01]\n",
      " [-6.86564028e-01 -4.14376855e-01  5.71402609e-01  1.74879205e+00\n",
      "  -5.36360741e-01 -1.85154963e+00  4.82694656e-01  1.54388392e+00\n",
      "  -2.09772325e+00  1.16269410e+00]\n",
      " [ 8.23860407e-01 -2.61721760e-01 -1.36973453e+00  1.31028891e+00\n",
      "  -2.03029364e-01 -4.57386732e-01 -3.62852842e-01 -7.10972965e-01\n",
      "   9.90884125e-01 -4.10594136e-01]\n",
      " [ 2.86207199e+00 -6.27916813e-01  2.30777338e-01  1.20353770e+00\n",
      "   3.73094767e-01 -4.14403021e-01  1.61255109e+00  1.38788354e+00\n",
      "  -1.02797961e+00  5.50458908e-01]\n",
      " [ 7.84263313e-01 -1.61723638e+00 -1.13021064e+00  1.32392392e-01\n",
      "  -4.48651910e-01 -1.52978814e+00  1.04882848e+00  5.95152736e-01\n",
      "  -1.05430894e-01 -1.13443160e+00]\n",
      " [-1.69061971e+00 -1.03190958e+00  1.57044396e-01  1.13290691e+00\n",
      "  -8.92964423e-01  9.13095415e-01 -2.21073461e+00 -3.35857272e-01\n",
      "   3.01979095e-01  3.49366486e-01]\n",
      " [-1.04290807e+00  1.65256470e-01 -6.92958891e-01 -2.53990024e-01\n",
      "  -3.19377363e-01  3.76329869e-01 -6.24551950e-03  1.95967662e+00\n",
      "  -5.85271001e-01 -5.94924271e-01]\n",
      " [ 5.72269738e-01  1.03361928e+00 -5.34319729e-02 -6.50938332e-01\n",
      "   6.08376503e-01  5.72085381e-01  1.43494582e+00  6.80320859e-01\n",
      "   3.79616112e-01 -1.11925572e-01]\n",
      " [ 1.15946507e+00  6.78941011e-01 -1.85618067e+00  3.86777878e-01\n",
      "   4.89136092e-02 -9.22971904e-01  1.98466194e+00  6.64021909e-01\n",
      "  -6.62926257e-01 -4.71699178e-01]\n",
      " [ 2.36681581e+00 -6.02015436e-01  6.90604806e-01  7.30161905e-01\n",
      "   1.41240394e+00 -1.42143798e+00  1.41409397e+00  8.83439720e-01\n",
      "   3.49786460e-01 -1.90935206e+00]\n",
      " [-5.04328430e-01 -5.51222503e-01 -1.94529963e+00 -1.47316813e-01\n",
      "   8.60699177e-01  6.88756227e-01 -6.95259631e-01 -2.76903272e-01\n",
      "   1.34761810e-01  1.52997896e-01]\n",
      " [ 4.36865002e-01 -6.61439836e-01 -1.96534550e+00 -8.90218973e-01\n",
      "   1.26993120e-01  6.67917430e-02 -4.83181387e-01 -3.25240254e-01\n",
      "   5.37807167e-01 -6.90943182e-01]\n",
      " [ 1.02599192e+00  8.17618847e-01  1.23553979e+00  9.85821307e-01\n",
      "   3.00758779e-01 -1.54451895e+00 -3.20344657e-01 -1.04461980e+00\n",
      "  -8.05201709e-01  3.58360440e-01]\n",
      " [ 8.16120028e-01 -9.71569598e-01 -5.53898253e-02  3.46678674e-01\n",
      "   4.07189071e-01 -1.68388158e-01 -9.97720003e-01 -1.44538915e+00\n",
      "   1.16388404e+00 -1.07951343e+00]\n",
      " [ 7.13301972e-02  6.33071184e-01 -1.15837026e+00 -9.65790927e-01\n",
      "   6.85449764e-02 -3.34284216e-01  5.33032238e-01 -7.21068263e-01\n",
      "  -6.83540940e-01 -1.54290915e-01]\n",
      " [ 3.66540760e-01 -2.63462722e-01  1.14508346e-01  6.43075109e-01\n",
      "   6.83016121e-01 -1.29236555e+00 -1.24511100e-01  3.03576052e-01\n",
      "   4.71627593e-01 -1.07260096e+00]\n",
      " [-5.69640279e-01 -2.07205486e+00 -2.89066225e-01  2.73984504e+00\n",
      "  -1.15993083e+00  7.54096389e-01  3.90899062e-01  8.91759396e-01\n",
      "   1.39503729e+00  8.25566351e-01]\n",
      " [-1.52252793e+00  1.55307996e+00 -3.47541034e-01  1.58317173e+00\n",
      "  -1.30693495e+00 -4.45402026e-01  1.69773828e-02 -7.40161061e-01\n",
      "  -1.40726447e+00 -1.44976974e-01]\n",
      " [ 2.67134041e-01 -1.15043509e+00  1.36589456e+00 -9.80790257e-01\n",
      "   1.31787813e+00  3.64618897e-01  1.38426960e+00 -1.65461886e+00\n",
      "   1.13151729e+00  8.62064242e-01]\n",
      " [ 4.93191093e-01 -5.11831284e-01 -2.31614053e-01 -2.68564439e+00\n",
      "  -9.73591447e-01 -3.90999317e-01  9.68131609e-03  9.32805240e-01\n",
      "   3.31182748e-01 -4.35122699e-01]\n",
      " [-8.61547470e-01 -2.34549984e-01 -1.93221271e-01 -1.06582940e+00\n",
      "   1.33575523e+00  9.64360833e-01 -6.11718655e-01  8.09482932e-01\n",
      "   1.47584200e+00  1.26314902e+00]\n",
      " [-9.41037536e-01 -9.11540091e-01 -2.24974895e+00  7.55146980e-01\n",
      "  -9.96465266e-01  1.04565513e+00  3.34429331e-02  7.90954083e-02\n",
      "   2.14182639e+00  1.57866463e-01]\n",
      " [-1.15281868e+00 -9.19997513e-01  9.42607999e-01 -4.80932474e-01\n",
      "  -2.25796536e-01 -2.59182632e-01  3.59588146e-01  1.09367633e+00\n",
      "  -2.15905476e+00  2.60308981e-01]\n",
      " [ 8.49813581e-01 -9.64369714e-01 -1.01987338e+00  1.08082604e+00\n",
      "  -2.94093877e-01 -7.69965649e-01 -2.94110370e+00  3.04507554e-01\n",
      "   8.98146033e-01 -1.20031095e+00]\n",
      " [-7.46962130e-01  1.14299214e+00 -8.03036809e-01  1.29205418e+00\n",
      "  -1.02887082e+00 -1.18161730e-01  7.05561042e-01 -1.36737442e+00\n",
      "   5.50454795e-01 -1.05273592e+00]\n",
      " [-1.07520068e+00 -1.39161813e+00 -9.58730578e-01  1.50912786e+00\n",
      "  -6.42755747e-01  2.79842347e-01  1.58768070e+00  4.38484609e-01\n",
      "   1.37853181e+00 -1.36729205e+00]\n",
      " [ 6.49274886e-02 -1.57741892e+00  1.38591051e+00  1.28318727e+00\n",
      "  -4.21534896e-01 -2.41323277e-01  1.82327700e+00  5.16319275e-01\n",
      "  -1.39645600e+00 -1.56091321e+00]\n",
      " [-7.12394416e-01 -2.19956017e+00 -4.65431809e-01  5.67437172e-01\n",
      "   8.30906272e-01  5.93311563e-02  4.51911241e-01 -1.01762867e+00\n",
      "  -7.56807506e-01 -3.12282532e-01]\n",
      " [-1.84223962e+00  2.16738686e-01 -2.44692832e-01  3.82542089e-02\n",
      "  -6.95649721e-03 -3.60412002e-01  1.04712594e+00 -8.50528121e-01\n",
      "   2.63664633e-01 -9.65189457e-01]\n",
      " [-5.41164696e-01 -1.28636706e+00 -6.11461818e-01 -8.43863666e-01\n",
      "  -1.75959952e-02 -1.72744179e+00 -1.93690157e+00  5.84081650e-01\n",
      "   8.71852636e-01  3.00898004e+00]\n",
      " [ 1.02857578e+00  7.30057657e-01 -7.72806346e-01  3.83642428e-02\n",
      "   4.60899174e-01  5.65081239e-01 -6.54464364e-01 -6.05151415e-01\n",
      "  -7.94184744e-01 -7.68752471e-02]\n",
      " [-9.56001163e-01 -6.34938836e-01  1.35261774e+00 -3.00577015e-01\n",
      "  -1.97344291e+00  2.41048098e-01 -2.23162994e-01  4.41579133e-01\n",
      "  -7.87625536e-02 -8.45844328e-01]\n",
      " [ 8.49962354e-01  1.67074156e+00 -8.18039477e-01 -4.97410446e-01\n",
      "   6.43421173e-01 -1.13952184e+00  1.12879562e+00  1.28054309e+00\n",
      "  -9.80688989e-01 -8.58915389e-01]\n",
      " [ 9.70977485e-01 -1.76602447e+00 -9.78706837e-01  5.52492917e-01\n",
      "   1.07661164e+00 -1.36462128e+00  1.86885560e+00 -2.54430249e-02\n",
      "   2.47737455e+00  6.96263373e-01]\n",
      " [-9.69863474e-01 -7.84729794e-03 -5.69388449e-01  6.98971152e-02\n",
      "  -3.99162062e-02  1.13653672e+00  1.75798595e+00  9.47047114e-01\n",
      "   9.64190185e-01 -6.31072223e-01]\n",
      " [-7.50208572e-02 -9.56939042e-01 -1.18391871e+00 -1.37874889e+00\n",
      "   2.29500461e+00  3.72038513e-01 -6.51211321e-01 -3.76205504e-01\n",
      "  -8.82564843e-01 -6.64287284e-02]\n",
      " [-2.19070211e-01  1.95504725e-01  2.90145189e-01 -2.58489519e-01\n",
      "  -1.46268494e-02 -5.63636482e-01  5.22442579e-01  4.24905092e-01\n",
      "  -4.98631060e-01  3.74322027e-01]\n",
      " [ 7.85697460e-01 -1.43532670e+00 -7.90159702e-01 -3.01514149e-01\n",
      "   2.39265180e+00  1.59303761e+00  2.50416338e-01  1.32139039e+00\n",
      "   1.26333213e+00  8.22504699e-01]\n",
      " [ 2.27280870e-01  1.03036487e+00 -1.80609548e+00 -3.01224023e-01\n",
      "  -1.24904609e+00 -1.08127308e+00  3.21459979e-01 -2.31490314e-01\n",
      "  -1.51854500e-01  5.76083064e-01]\n",
      " [ 8.51262093e-01  1.29208541e+00  4.74668086e-01  3.41997027e-01\n",
      "  -1.36283660e+00 -1.17006564e+00 -4.39065814e-01 -1.24206161e+00\n",
      "  -9.45987880e-01 -5.55834472e-01]\n",
      " [ 6.27460629e-02 -3.24156940e-01 -9.30367112e-01  1.20580721e+00\n",
      "   1.05755103e+00  1.41755211e+00  6.61064267e-01  2.00113729e-01\n",
      "  -7.29067326e-01 -7.66903579e-01]\n",
      " [ 3.11166763e-01 -4.67960805e-01 -1.50228286e+00  9.80292797e-01\n",
      "  -3.35854769e-01 -8.80563706e-02  1.50037014e+00 -1.20245598e-01\n",
      "  -1.73732236e-01 -9.50503409e-01]\n",
      " [-4.30312067e-01  2.72705853e-01  1.36298311e+00 -3.24015111e-01\n",
      "   1.84848532e-02  6.29720747e-01 -7.04475760e-01  8.29195917e-01\n",
      "  -1.82550764e+00 -2.18607378e+00]\n",
      " [ 9.53653216e-01  7.70970941e-01  4.17818367e-01  5.56612313e-01\n",
      "  -9.71334696e-01 -9.44722444e-02 -5.32121778e-01  5.37463129e-01\n",
      "  -1.10129535e+00 -9.45933104e-01]\n",
      " [ 2.28943691e-01 -4.57636863e-02  4.70252842e-01 -2.30596900e+00\n",
      "  -3.09780419e-01 -4.00582403e-01  3.63013476e-01 -4.27911848e-01\n",
      "   9.44231868e-01  9.60246697e-02]\n",
      " [ 4.08519030e-01  4.86775994e-01  3.23530436e-01  8.90504301e-01\n",
      "  -7.11275697e-01 -1.95768404e+00 -1.30118263e+00 -5.19278884e-01\n",
      "   7.85086691e-01  4.00133073e-01]\n",
      " [ 3.66467327e-01  7.29635596e-01 -2.03148341e+00 -1.32864165e+00\n",
      "  -4.59927261e-01 -1.86461353e+00 -3.13303828e-01  6.51517138e-02\n",
      "  -3.64996403e-01 -3.51200670e-01]\n",
      " [-7.07448721e-01 -2.23599806e-01  1.04517221e+00  3.57282981e-02\n",
      "  -1.97898567e-01 -1.26614869e-01 -1.23052172e-01 -5.28027534e-01\n",
      "   4.67751086e-01 -8.10107887e-01]\n",
      " [ 4.04890209e-01  5.90511024e-01  6.22246623e-01 -5.25192380e-01\n",
      "  -4.59761590e-01  2.05420837e-01  7.91529059e-01 -1.11185479e+00\n",
      "   1.11659038e+00 -8.46724212e-02]\n",
      " [-3.29506621e-02 -1.10272384e+00  1.05962133e+00 -6.47622585e-01\n",
      "  -1.12380099e+00 -9.51195896e-01  6.16370514e-02  1.08735490e+00\n",
      "  -1.59984505e+00 -1.07327056e+00]\n",
      " [-1.94244325e-01 -2.55246550e-01 -1.10913599e+00  3.30776989e-01\n",
      "   1.34737396e+00  1.66512489e+00 -7.73749948e-02 -8.79342973e-01\n",
      "  -1.50864080e-01 -1.66060603e+00]\n",
      " [ 5.13065338e-01  8.50268364e-01  1.17833054e+00  1.88484211e-02\n",
      "   4.81196582e-01  1.17187476e+00  3.33013356e-01 -3.46278399e-01\n",
      "  -1.54391974e-02 -1.94289088e+00]\n",
      " [ 1.40534878e+00 -2.61992621e+00 -7.12226450e-01 -2.02565446e-01\n",
      "  -6.63629293e-01  8.64818394e-02  2.93360800e-01 -1.46040130e+00\n",
      "  -1.24281752e+00  2.69441873e-01]\n",
      " [ 1.93214118e-01  1.16719482e-02 -1.93927169e-01 -4.04520988e-01\n",
      "  -2.17881560e+00 -3.76738787e-01  8.86258930e-02 -2.46797770e-01\n",
      "   1.00658488e+00  8.70578289e-02]\n",
      " [-3.28769594e-01 -3.60245019e-01 -4.33026114e-03 -4.93486524e-01\n",
      "   1.52155066e+00 -1.46527195e+00  2.42219305e+00 -1.69279552e+00\n",
      "   7.44432509e-02  1.58331764e+00]\n",
      " [ 1.88688195e+00 -5.17465889e-01  6.01731598e-01  1.14832497e+00\n",
      "   3.16561908e-01 -1.96978939e+00  5.17948329e-01  1.34104609e+00\n",
      "   1.53447831e+00 -1.06213975e+00]\n",
      " [-2.73272097e-01  1.43480852e-01 -1.19612408e+00 -1.23083405e-01\n",
      "  -1.98460639e-01  3.03752143e-02 -3.63570869e-01 -5.45863211e-01\n",
      "  -8.30996454e-01  5.64566553e-01]\n",
      " [-2.71047890e-01 -1.44236720e+00 -2.83538342e-01  6.78340316e-01\n",
      "   4.66340184e-01  2.25778770e+00 -6.80646539e-01 -2.59877890e-01\n",
      "   1.03324234e+00 -3.75026107e-01]\n",
      " [ 7.01576948e-01  1.32300150e+00 -8.46283078e-01  1.44625604e+00\n",
      "   6.28034413e-01 -1.48502082e-01  1.60509959e-01 -8.74935627e-01\n",
      "   7.99329162e-01 -2.97647268e-01]\n",
      " [ 3.44176054e-01  1.94848740e+00 -4.61372703e-01 -3.34428847e-01\n",
      "   1.21642375e+00 -1.07672083e+00  4.21982944e-01 -7.47801900e-01\n",
      "  -7.10466266e-01 -1.12570393e+00]\n",
      " [ 4.59289610e-01  2.51107883e+00 -9.12421167e-01  6.77192688e-01\n",
      "  -3.11057389e-01 -1.65801966e+00  3.20321739e-01  6.21120036e-01\n",
      "   2.82818168e-01  2.05868781e-01]\n",
      " [-8.75108540e-02  3.41434538e-01 -2.59540606e+00 -3.91767621e-01\n",
      "  -2.34737706e+00  1.09452200e+00 -8.83132219e-01 -3.46112609e-01\n",
      "  -7.49299109e-01  6.28453970e-01]\n",
      " [ 5.97821534e-01 -6.06942952e-01 -7.69931436e-01  3.12222205e-02\n",
      "   7.73286104e-01 -5.46515346e-01 -2.52264833e+00  9.74063337e-01\n",
      "  -1.72870231e+00  7.84687281e-01]\n",
      " [-3.09706151e-01 -1.33551872e+00 -1.30495280e-01 -2.44129348e+00\n",
      "  -1.29481837e-01  4.58274007e-01  4.31580305e-01 -1.14207149e+00\n",
      "  -8.16950262e-01  3.05594742e-01]\n",
      " [ 5.67024887e-01 -9.06855226e-01  2.66388934e-02 -5.03674150e-01\n",
      "   5.29500283e-02 -1.96468973e+00  1.04272950e+00  1.14949334e+00\n",
      "  -6.43563986e-01 -1.48319542e+00]\n",
      " [ 1.12891579e+00 -8.81499052e-01 -2.88248658e-01 -5.90398908e-01\n",
      "   8.82867277e-01  1.81749606e+00  1.27206600e+00  3.08950663e-01\n",
      "   1.74922669e+00 -1.58374429e+00]\n",
      " [ 9.07457694e-02  5.32308996e-01  1.02961993e+00  4.83681485e-02\n",
      "  -3.57724696e-01  1.30898511e+00 -1.88400090e-01  9.97227788e-01\n",
      "   1.87313765e-01  8.32972705e-01]\n",
      " [-8.57725918e-01 -7.73551464e-01  1.24603558e+00 -1.03472626e+00\n",
      "   2.05168819e+00 -6.59403086e-01  6.95523694e-02 -1.81479499e-01\n",
      "   7.22745419e-01 -9.63726714e-02]\n",
      " [ 4.14142996e-01  7.38706410e-01 -1.05683386e+00 -3.74298871e-01\n",
      "  -5.62677324e-01  1.71903789e-01 -5.59590049e-02 -8.84464383e-01\n",
      "  -1.30444825e+00  1.56442475e+00]\n",
      " [-1.27763963e+00  1.07376003e+00 -5.40432155e-01 -1.62269974e+00\n",
      "   5.25648594e-01 -5.34960985e-01  7.86956251e-01 -1.30081832e-01\n",
      "   6.28457606e-01 -7.86677659e-01]\n",
      " [-1.41851097e-01  6.85200393e-01 -1.34521425e-01  7.90476918e-01\n",
      "   1.04809809e+00  7.34769702e-01  1.16738892e+00 -5.68735301e-01\n",
      "  -2.59367555e-01  3.25127810e-01]\n",
      " [-5.02667248e-01 -1.48585284e+00 -2.72327483e-01  2.97310889e-01\n",
      "   1.34957957e+00 -4.26292896e+00 -4.82845753e-02 -9.17852998e-01\n",
      "  -2.23147106e+00 -4.66902614e-01]\n",
      " [ 4.21025842e-01  2.50764668e-01 -6.37442708e-01  5.12491763e-01\n",
      "   5.32104909e-01 -6.45899773e-01  1.09386396e+00 -1.28360260e+00\n",
      "  -3.88377011e-01 -6.78571403e-01]\n",
      " [-3.76013011e-01 -3.02209258e-01  2.83490324e+00  1.19519186e+00\n",
      "   3.07227410e-02 -3.64545196e-01 -3.91735077e-01  9.82932448e-01\n",
      "  -5.24716973e-01 -2.19607465e-02]\n",
      " [ 8.67887199e-01  9.80096579e-01  4.50062513e-01  6.43981993e-01\n",
      "   5.09480596e-01  1.10309184e+00 -1.38008162e-01 -7.28034601e-02\n",
      "   1.07363440e-01 -6.76613212e-01]\n",
      " [ 5.39811552e-01  1.36735213e+00 -1.23268771e+00 -6.16443396e-01\n",
      "   6.71286166e-01 -1.59369338e+00  8.00358415e-01  1.76579070e+00\n",
      "  -4.19767611e-02  1.46533656e+00]\n",
      " [-2.27573299e+00  6.72405362e-02  1.68860584e-01  4.41864759e-01\n",
      "   6.81791306e-02  6.21414721e-01  6.00661099e-01 -4.74143773e-01\n",
      "   1.04847085e+00  1.92317665e+00]\n",
      " [ 7.51722872e-01 -4.64101881e-01  8.01218092e-01  4.65288252e-01\n",
      "  -6.96651042e-01 -1.06534839e+00  6.69967651e-01  6.78819656e-01\n",
      "   2.47535557e-01  2.84743845e-01]\n",
      " [-1.15246117e+00  4.54570316e-02  6.26210868e-01 -1.77622950e+00\n",
      "  -1.42692673e+00  9.43153620e-01 -2.28801936e-01  1.01852581e-01\n",
      "   1.22767031e+00 -1.55146778e+00]\n",
      " [ 9.31205526e-02 -1.11669695e+00 -8.98081422e-01  7.96740174e-01\n",
      "   1.29639006e+00 -5.43512523e-01  6.00334883e-01 -1.26244962e+00\n",
      "   5.20490766e-01  1.54303713e-03]\n",
      " [-1.88770199e+00 -6.77099347e-01 -1.57965791e+00 -1.70109570e+00\n",
      "  -4.56233695e-02  6.31569088e-01  6.76050782e-02  1.57014120e+00\n",
      "   1.70830142e+00  4.77673441e-01]\n",
      " [ 1.92412555e-01  1.11088169e+00  8.44269693e-01 -6.88789308e-01\n",
      "  -1.71272469e+00 -1.95826709e-01 -6.36704683e-01  7.10142180e-02\n",
      "  -3.25508326e-01 -2.18236995e+00]\n",
      " [ 7.61419713e-01  1.79674327e+00  3.66644859e-01  7.33138084e-01\n",
      "  -8.77591908e-01  1.24692035e+00 -3.90033305e-01  4.97528791e-01\n",
      "   1.06677663e+00  9.47952986e-01]\n",
      " [-3.63182217e-01  7.10594177e-01 -4.38976794e-01 -1.10790062e+00\n",
      "   2.51863718e-01  2.85132170e-01 -4.34082538e-01 -1.27589726e+00\n",
      "   9.20423985e-01 -6.95282876e-01]\n",
      " [-9.57859516e-01 -1.28193414e+00 -8.94765079e-01  6.14530891e-02\n",
      "   1.35826182e+00 -4.51761097e-01  5.28805137e-01  3.81112128e-01\n",
      "  -1.36779273e+00  1.72022510e+00]\n",
      " [-8.88912082e-01 -2.71753147e-02  1.08175910e+00 -4.60762978e-01\n",
      "  -2.23676705e+00  2.36899638e+00 -3.75922829e-01  6.24727130e-01\n",
      "   1.77098083e+00  1.28001916e+00]\n",
      " [ 9.73326921e-01 -1.26848876e+00 -1.68239689e+00  5.38962185e-01\n",
      "  -6.88754380e-01 -6.33546948e-01 -1.80753124e+00 -6.78770244e-02\n",
      "   4.61835414e-01 -7.99623311e-01]\n",
      " [ 1.05048573e+00  4.01527137e-01 -1.54012513e+00 -8.49522352e-01\n",
      "   3.24638486e-01  1.14821278e-01  2.09740233e+00 -5.29460847e-01\n",
      "  -1.46938884e+00 -1.63845229e+00]\n",
      " [-9.21806574e-01  1.20926964e+00 -2.33110026e-01 -1.80372691e+00\n",
      "  -8.53399456e-01 -6.42380655e-01  1.14485025e+00 -1.18663156e+00\n",
      "   1.21727884e+00 -1.19987786e+00]\n",
      " [-8.35805893e-01 -5.13409317e-01  4.24718499e-01  2.56493658e-01\n",
      "  -8.06616768e-02  1.83292657e-01  3.76052260e-01  1.53563157e-01\n",
      "   1.07263350e+00 -6.70157492e-01]\n",
      " [-6.78693831e-01 -8.45169961e-01  2.00893387e-01  4.09664333e-01\n",
      "   2.65991896e-01  2.53284484e-01  6.00396931e-01 -5.16012251e-01\n",
      "   5.37337363e-01  1.47814012e+00]\n",
      " [-5.54634571e-01  1.33239043e+00 -1.23388624e+00  1.08421743e+00\n",
      "  -8.96998703e-01  3.66718173e-01 -1.06441461e-01  6.48594916e-01\n",
      "  -1.18441868e+00 -1.44233894e+00]\n",
      " [ 2.11943150e+00  1.92640698e+00 -1.30694258e+00  4.42890942e-01\n",
      "  -2.37134084e-01  2.02311277e-01  1.44500837e-01  4.48059201e-01\n",
      "  -1.98534143e+00  6.87737226e-01]\n",
      " [ 7.36559451e-01  5.62239647e-01  2.55762100e-01 -7.07544327e-01\n",
      "  -9.70442474e-01 -1.35880005e+00 -3.75339746e-01 -1.46508265e+00\n",
      "   4.93939698e-01  9.31736946e-01]\n",
      " [ 1.03067088e+00  5.69151402e-01 -4.37685102e-01  8.46174538e-01\n",
      "  -9.03026640e-01 -1.43620050e+00  1.40418327e+00  1.61556828e+00\n",
      "  -9.64766979e-01  8.83565605e-01]\n",
      " [ 4.28469449e-01 -2.92300910e-01 -7.67014265e-01  1.13527596e-01\n",
      "  -6.27940536e-01 -7.41278112e-01  3.26591611e-01  1.25144437e-01\n",
      "   1.25055277e+00 -5.40876091e-01]\n",
      " [-1.36172497e+00  7.45451450e-01 -9.20491099e-01  1.25879490e+00\n",
      "   1.72221828e+00  3.60262722e-01  3.04744095e-01  7.46320307e-01\n",
      "   7.82758832e-01 -1.21058834e+00]\n",
      " [ 1.30692196e+00  6.99505657e-02  4.03011948e-01  1.93203640e+00\n",
      "   2.05312276e+00 -1.29478037e+00 -6.29896045e-01  1.06151044e+00\n",
      "   9.19141024e-02  1.06165910e+00]], shape=(100, 10), dtype=float32)\n",
      "Initial loss: 149.791\n",
      "Loss at step 000: 82.626\n",
      "Num =  1\n",
      "Final loss: 80.808\n",
      "0.99769443\n",
      "0.022457898\n",
      "Prediction loss: 135.005\n",
      "Initial loss: 141.111\n",
      "Loss at step 000: 72.738\n",
      "Num =  2\n",
      "Final loss: 70.526\n",
      "0.95536643\n",
      "0.02587208\n",
      "Prediction loss: 137.834\n",
      "Initial loss: 185.468\n",
      "Loss at step 000: 81.296\n",
      "Num =  3\n",
      "Final loss: 74.387\n",
      "1.0191607\n",
      "-0.027545013\n",
      "Prediction loss: 149.902\n",
      "Initial loss: 179.569\n",
      "Loss at step 000: 75.885\n",
      "Num =  4\n",
      "Final loss: 69.992\n",
      "0.9811599\n",
      "-0.023307389\n",
      "Prediction loss: 145.806\n",
      "Initial loss: 142.481\n",
      "Loss at step 000: 73.547\n",
      "Num =  5\n",
      "Final loss: 70.274\n",
      "0.9993005\n",
      "0.062214736\n",
      "Prediction loss: 190.959\n",
      "Initial loss: 174.281\n",
      "Loss at step 000: 76.514\n",
      "Num =  6\n",
      "Final loss: 65.886\n",
      "1.0233059\n",
      "0.027367225\n",
      "Prediction loss: 259.538\n",
      "Initial loss: 146.405\n",
      "Loss at step 000: 71.768\n",
      "Num =  7\n",
      "Final loss: 67.879\n",
      "0.9893204\n",
      "0.08313127\n",
      "Prediction loss: 218.925\n",
      "Initial loss: 123.426\n",
      "Loss at step 000: 77.500\n",
      "Num =  8\n",
      "Final loss: 74.099\n",
      "1.0182498\n",
      "0.023357378\n",
      "Prediction loss: 95.974\n",
      "Initial loss: 170.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 000: 76.364\n",
      "Num =  9\n",
      "Final loss: 73.513\n",
      "0.9771462\n",
      "0.06495246\n",
      "Prediction loss: 189.062\n",
      "Initial loss: 118.219\n",
      "Loss at step 000: 72.912\n",
      "Num =  10\n",
      "Final loss: 68.787\n",
      "1.0675489\n",
      "0.05144222\n",
      "Prediction loss: 196.522\n",
      "tf.Tensor(\n",
      "[[ 1.6104683   2.5445693  -1.4694464  ...  1.4199134  -0.64055353\n",
      "   1.3200046 ]\n",
      " [-0.9034714   0.4682869   0.941384   ...  0.4231634   0.09292985\n",
      "  -0.24124624]\n",
      " [-0.8483676  -0.1393245  -1.3653072  ...  1.0478908   0.634427\n",
      "   1.3203015 ]\n",
      " ...\n",
      " [-1.0836625  -1.1132107   1.0161939  ...  0.123207    0.13083833\n",
      "   3.0408661 ]\n",
      " [-1.1691477   0.24665685  0.43659925 ...  0.65189385 -1.2391926\n",
      "  -0.35691345]\n",
      " [ 1.1672319  -0.5737275  -0.23040141 ... -0.7564651   0.35014948\n",
      "  -1.2475421 ]], shape=(100, 15), dtype=float32)\n",
      "Initial loss: 184.473\n",
      "Loss at step 000: 93.267\n",
      "Num =  1\n",
      "Final loss: 84.870\n",
      "1.0020466\n",
      "-0.029896373\n",
      "Prediction loss: 268.773\n",
      "Initial loss: 163.146\n",
      "Loss at step 000: 102.001\n",
      "Num =  2\n",
      "Final loss: 94.328\n",
      "1.0055972\n",
      "-0.013832947\n",
      "Prediction loss: 105.501\n",
      "Initial loss: 147.774\n",
      "Loss at step 000: 93.186\n",
      "Num =  3\n",
      "Final loss: 89.022\n",
      "1.0054392\n",
      "-0.0056558433\n",
      "Prediction loss: 173.956\n",
      "Initial loss: 178.107\n",
      "Loss at step 000: 91.574\n",
      "Num =  4\n",
      "Final loss: 80.437\n",
      "0.9759819\n",
      "-0.015667845\n",
      "Prediction loss: 119.882\n",
      "Initial loss: 175.384\n",
      "Loss at step 000: 92.445\n",
      "Num =  5\n",
      "Final loss: 83.908\n",
      "0.9855984\n",
      "-0.015993122\n",
      "Prediction loss: 162.566\n",
      "Initial loss: 173.371\n",
      "Loss at step 000: 92.635\n",
      "Num =  6\n",
      "Final loss: 87.783\n",
      "1.0014838\n",
      "-0.00032772985\n",
      "Prediction loss: 160.992\n",
      "Initial loss: 184.786\n",
      "Loss at step 000: 109.317\n",
      "Num =  7\n",
      "Final loss: 103.895\n",
      "1.0057877\n",
      "-0.013770545\n",
      "Prediction loss: 128.809\n",
      "Initial loss: 166.484\n",
      "Loss at step 000: 97.716\n",
      "Num =  8\n",
      "Final loss: 92.417\n",
      "0.98482215\n",
      "0.002761205\n",
      "Prediction loss: 232.065\n",
      "Initial loss: 165.333\n",
      "Loss at step 000: 100.069\n",
      "Num =  9\n",
      "Final loss: 85.799\n",
      "0.98429585\n",
      "-0.0129025355\n",
      "Prediction loss: 176.694\n",
      "Initial loss: 188.338\n",
      "Loss at step 000: 96.898\n",
      "Num =  10\n",
      "Final loss: 85.347\n",
      "1.0182464\n",
      "0.011301099\n",
      "Prediction loss: 177.424\n",
      "tf.Tensor(\n",
      "[[-0.61946285 -0.44788346  0.21846302 ...  0.97086066  1.9611577\n",
      "  -0.4119017 ]\n",
      " [-2.6921294   0.11256839  1.766642   ...  0.6924947   0.84510154\n",
      "  -0.40618953]\n",
      " [ 0.62705314 -0.22398025 -0.06080254 ...  0.6250929  -0.9238574\n",
      "   0.21673381]\n",
      " ...\n",
      " [-2.443789   -1.3160605  -0.28808495 ...  0.60335094 -0.5130206\n",
      "   1.4666291 ]\n",
      " [-1.655711   -0.0893416   1.7958367  ... -0.6633685  -1.2418813\n",
      "   0.31761467]\n",
      " [-1.0674337  -1.7646643  -1.4270102  ... -1.8183099   0.5871609\n",
      "  -0.10335413]], shape=(100, 20), dtype=float32)\n",
      "Initial loss: 169.205\n",
      "Loss at step 000: 106.878\n",
      "Num =  1\n",
      "Final loss: 94.647\n",
      "1.0130523\n",
      "0.027613927\n",
      "Prediction loss: 114.757\n",
      "Initial loss: 172.367\n",
      "Loss at step 000: 104.607\n",
      "Num =  2\n",
      "Final loss: 89.548\n",
      "1.005068\n",
      "-0.0022802085\n",
      "Prediction loss: 200.905\n",
      "Initial loss: 165.500\n",
      "Loss at step 000: 106.333\n",
      "Num =  3\n",
      "Final loss: 92.007\n",
      "0.98904365\n",
      "-0.03134224\n",
      "Prediction loss: 183.941\n",
      "Initial loss: 151.220\n",
      "Loss at step 000: 99.839\n",
      "Num =  4\n",
      "Final loss: 85.456\n",
      "1.002758\n",
      "0.00050168537\n",
      "Prediction loss: 144.536\n",
      "Initial loss: 173.275\n",
      "Loss at step 000: 108.210\n",
      "Num =  5\n",
      "Final loss: 97.314\n",
      "1.0170561\n",
      "0.033665065\n",
      "Prediction loss: 131.038\n",
      "Initial loss: 194.579\n",
      "Loss at step 000: 98.984\n",
      "Num =  6\n",
      "Final loss: 78.851\n",
      "1.0063406\n",
      "-0.008167482\n",
      "Prediction loss: 106.642\n",
      "Initial loss: 178.675\n",
      "Loss at step 000: 99.220\n",
      "Num =  7\n",
      "Final loss: 83.000\n",
      "0.96233934\n",
      "-0.018719606\n",
      "Prediction loss: 97.675\n",
      "Initial loss: 180.871\n",
      "Loss at step 000: 95.350\n",
      "Num =  8\n",
      "Final loss: 78.258\n",
      "0.9917701\n",
      "-0.015956039\n",
      "Prediction loss: 174.904\n",
      "Initial loss: 162.453\n",
      "Loss at step 000: 99.614\n",
      "Num =  9\n",
      "Final loss: 88.098\n",
      "0.97875905\n",
      "0.00079689693\n",
      "Prediction loss: 173.774\n",
      "Initial loss: 183.928\n",
      "Loss at step 000: 102.054\n",
      "Num =  10\n",
      "Final loss: 87.813\n",
      "1.0060577\n",
      "-0.012246417\n",
      "Prediction loss: 115.132\n",
      "tf.Tensor(\n",
      "[[ 0.34017172  1.2389973   0.4386408  ...  0.39235076  0.07439324\n",
      "  -0.06768174]\n",
      " [-1.0249448  -0.6137548   0.58271086 ...  0.9027875  -0.7563125\n",
      "   0.02968094]\n",
      " [-0.8964469   0.37207907  0.47409075 ...  0.30777323 -1.1239806\n",
      "  -1.6924093 ]\n",
      " ...\n",
      " [ 0.7560114  -0.25419176  1.453495   ...  0.4792644  -1.0286613\n",
      "   0.5900316 ]\n",
      " [-0.27076912  0.14701933  0.47739926 ... -0.6212064   2.5127065\n",
      "   0.9304278 ]\n",
      " [-3.3210957  -0.19062461  0.3269257  ... -0.4898958  -1.4185604\n",
      "  -1.5310208 ]], shape=(100, 25), dtype=float32)\n",
      "Initial loss: 150.900\n",
      "Loss at step 000: 96.871\n",
      "Num =  1\n",
      "Final loss: 77.467\n",
      "0.98757577\n",
      "0.0054894537\n",
      "Prediction loss: 113.564\n",
      "Initial loss: 152.662\n",
      "Loss at step 000: 90.645\n",
      "Num =  2\n",
      "Final loss: 71.256\n",
      "1.0054357\n",
      "-0.007834061\n",
      "Prediction loss: 84.577\n",
      "Initial loss: 141.306\n",
      "Loss at step 000: 81.736\n",
      "Num =  3\n",
      "Final loss: 67.319\n",
      "1.0042421\n",
      "0.031355605\n",
      "Prediction loss: 112.547\n",
      "Initial loss: 156.672\n",
      "Loss at step 000: 97.233\n",
      "Num =  4\n",
      "Final loss: 75.505\n",
      "0.971988\n",
      "0.021300925\n",
      "Prediction loss: 129.337\n",
      "Initial loss: 157.393\n",
      "Loss at step 000: 91.548\n",
      "Num =  5\n",
      "Final loss: 74.042\n",
      "0.9826646\n",
      "0.000110247995\n",
      "Prediction loss: 114.961\n",
      "Initial loss: 160.719\n",
      "Loss at step 000: 91.927\n",
      "Num =  6\n",
      "Final loss: 74.320\n",
      "0.9782597\n",
      "-0.029317945\n",
      "Prediction loss: 93.673\n",
      "Initial loss: 165.566\n",
      "Loss at step 000: 94.825\n",
      "Num =  7\n",
      "Final loss: 69.973\n",
      "1.0043149\n",
      "0.032528732\n",
      "Prediction loss: 127.091\n",
      "Initial loss: 166.910\n",
      "Loss at step 000: 95.595\n",
      "Num =  8\n",
      "Final loss: 73.623\n",
      "0.9564207\n",
      "0.005439453\n",
      "Prediction loss: 99.971\n",
      "Initial loss: 160.129\n",
      "Loss at step 000: 91.548\n",
      "Num =  9\n",
      "Final loss: 72.630\n",
      "0.9833462\n",
      "-0.008482483\n",
      "Prediction loss: 83.382\n",
      "Initial loss: 158.455\n",
      "Loss at step 000: 92.720\n",
      "Num =  10\n",
      "Final loss: 73.717\n",
      "0.97988665\n",
      "-0.0012808713\n",
      "Prediction loss: 110.260\n",
      "tf.Tensor(\n",
      "[[-1.0269669   1.2844715   0.6657094  ...  0.7686747  -0.913758\n",
      "  -1.1598837 ]\n",
      " [-1.745991   -1.7194319   2.2598743  ... -0.0626656   0.1838431\n",
      "  -0.09586067]\n",
      " [ 0.45522377 -0.56027037  0.63008547 ... -0.19662532  0.52631414\n",
      "   0.9477021 ]\n",
      " ...\n",
      " [ 0.4313486   1.1979716   0.22326112 ... -0.9013456   0.6307461\n",
      "  -1.6965867 ]\n",
      " [-0.39875928 -1.1874845   0.11682248 ... -0.35597375 -0.30229634\n",
      "   2.2453413 ]\n",
      " [-0.39185587  0.15633745 -0.57951665 ... -0.5365065  -0.760437\n",
      "  -1.0904019 ]], shape=(100, 30), dtype=float32)\n",
      "Initial loss: 141.974\n",
      "Loss at step 000: 86.016\n",
      "Num =  1\n",
      "Final loss: 57.966\n",
      "0.98650587\n",
      "0.007252916\n",
      "Prediction loss: 196.757\n",
      "Initial loss: 134.098\n",
      "Loss at step 000: 86.861\n",
      "Num =  2\n",
      "Final loss: 63.724\n",
      "1.007893\n",
      "-0.0141349705\n",
      "Prediction loss: 211.770\n",
      "Initial loss: 125.672\n",
      "Loss at step 000: 79.051\n",
      "Num =  3\n",
      "Final loss: 56.222\n",
      "1.0030476\n",
      "-0.012282044\n",
      "Prediction loss: 195.106\n",
      "Initial loss: 143.094\n",
      "Loss at step 000: 90.457\n",
      "Num =  4\n",
      "Final loss: 67.498\n",
      "0.99841774\n",
      "-0.035168696\n",
      "Prediction loss: 176.934\n",
      "Initial loss: 117.222\n",
      "Loss at step 000: 79.583\n",
      "Num =  5\n",
      "Final loss: 60.725\n",
      "1.0185359\n",
      "0.016172493\n",
      "Prediction loss: 198.027\n",
      "Initial loss: 130.702\n",
      "Loss at step 000: 80.888\n",
      "Num =  6\n",
      "Final loss: 58.831\n",
      "0.9722235\n",
      "-0.034761976\n",
      "Prediction loss: 167.373\n",
      "Initial loss: 147.170\n",
      "Loss at step 000: 91.103\n",
      "Num =  7\n",
      "Final loss: 68.298\n",
      "0.9748763\n",
      "-0.013199859\n",
      "Prediction loss: 228.059\n",
      "Initial loss: 140.484\n",
      "Loss at step 000: 85.235\n",
      "Num =  8\n",
      "Final loss: 59.611\n",
      "1.0009592\n",
      "-0.010137268\n",
      "Prediction loss: 256.056\n",
      "Initial loss: 139.077\n",
      "Loss at step 000: 91.076\n",
      "Num =  9\n",
      "Final loss: 66.573\n",
      "0.99708354\n",
      "-0.0031233234\n",
      "Prediction loss: 180.079\n",
      "Initial loss: 139.209\n",
      "Loss at step 000: 86.807\n",
      "Num =  10\n",
      "Final loss: 61.515\n",
      "0.9991037\n",
      "-0.031224336\n",
      "Prediction loss: 202.251\n",
      "tf.Tensor(\n",
      "[[ 0.14686002 -0.98909545 -2.7037058  ...  0.58883035  0.40386626\n",
      "  -0.6839379 ]\n",
      " [-0.6161054  -0.09179009  0.66400194 ... -0.48338374  0.36358917\n",
      "   0.22362252]\n",
      " [-1.3053843  -1.5607454  -1.0657256  ... -0.24622537 -0.78313226\n",
      "  -0.21745075]\n",
      " ...\n",
      " [ 1.222816   -1.9009497   0.43397397 ... -0.5850298   1.0086104\n",
      "   0.1062077 ]\n",
      " [-0.4623727   0.94954944 -0.4459818  ... -1.5161438   0.08416583\n",
      "  -1.2734816 ]\n",
      " [-0.02462131  1.0112643  -0.67087203 ... -0.9603782  -0.21476169\n",
      "  -0.76355964]], shape=(100, 35), dtype=float32)\n",
      "Initial loss: 151.270\n",
      "Loss at step 000: 102.798\n",
      "Num =  1\n",
      "Final loss: 72.262\n",
      "1.0126008\n",
      "-0.0073971394\n",
      "Prediction loss: 156.806\n",
      "Initial loss: 154.957\n",
      "Loss at step 000: 108.389\n",
      "Loss at step 020: 79.117\n",
      "Num =  2\n",
      "Final loss: 79.113\n",
      "0.9952544\n",
      "0.016914109\n",
      "Prediction loss: 199.121\n",
      "Initial loss: 156.496\n",
      "Loss at step 000: 109.425\n",
      "Num =  3\n",
      "Final loss: 80.260\n",
      "0.97939956\n",
      "0.009617932\n",
      "Prediction loss: 183.890\n",
      "Initial loss: 142.666\n",
      "Loss at step 000: 102.221\n",
      "Loss at step 020: 79.502\n",
      "Num =  4\n",
      "Final loss: 79.502\n",
      "0.97750324\n",
      "-0.009645201\n",
      "Prediction loss: 138.738\n",
      "Initial loss: 162.515\n",
      "Loss at step 000: 110.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num =  5\n",
      "Final loss: 79.149\n",
      "0.99037844\n",
      "0.016248828\n",
      "Prediction loss: 206.046\n",
      "Initial loss: 162.281\n",
      "Loss at step 000: 111.504\n",
      "Loss at step 020: 77.844\n",
      "Num =  6\n",
      "Final loss: 77.842\n",
      "0.9943573\n",
      "-0.010507405\n",
      "Prediction loss: 157.739\n",
      "Initial loss: 151.271\n",
      "Loss at step 000: 102.917\n",
      "Num =  7\n",
      "Final loss: 71.395\n",
      "0.9790291\n",
      "0.010568721\n",
      "Prediction loss: 228.823\n",
      "Initial loss: 160.998\n",
      "Loss at step 000: 105.589\n",
      "Num =  8\n",
      "Final loss: 76.224\n",
      "0.9984813\n",
      "0.004540307\n",
      "Prediction loss: 197.665\n",
      "Initial loss: 178.821\n",
      "Loss at step 000: 112.690\n",
      "Num =  9\n",
      "Final loss: 73.668\n",
      "0.99103534\n",
      "0.011895415\n",
      "Prediction loss: 197.109\n",
      "Initial loss: 164.405\n",
      "Loss at step 000: 111.373\n",
      "Num =  10\n",
      "Final loss: 83.530\n",
      "0.98992693\n",
      "0.02800188\n",
      "Prediction loss: 161.454\n",
      "tf.Tensor(\n",
      "[[-0.91745186 -0.8507073  -1.196654   ...  0.01153643 -1.82891\n",
      "   2.3350637 ]\n",
      " [ 1.1588097  -1.0289447   0.42066225 ...  0.09777636  0.6131101\n",
      "  -0.9025082 ]\n",
      " [ 0.50669867  0.22508562 -2.7913465  ...  2.0826278   1.3267516\n",
      "  -0.83593553]\n",
      " ...\n",
      " [ 1.0194005  -1.3321211  -1.2275462  ...  1.7380196   0.00991732\n",
      "  -0.04884264]\n",
      " [ 0.9573268  -1.548159   -0.2441007  ... -0.33015522 -1.2396826\n",
      "  -0.2514337 ]\n",
      " [-0.57968915  1.1479914   2.548953   ...  0.30595157 -0.15373726\n",
      "   0.08856846]], shape=(100, 40), dtype=float32)\n",
      "Initial loss: 162.513\n",
      "Loss at step 000: 110.803\n",
      "Num =  1\n",
      "Final loss: 74.096\n",
      "1.0118229\n",
      "0.005184826\n",
      "Prediction loss: 209.469\n",
      "Initial loss: 160.575\n",
      "Loss at step 000: 109.076\n",
      "Num =  2\n",
      "Final loss: 74.008\n",
      "0.9766145\n",
      "-0.024957817\n",
      "Prediction loss: 190.423\n",
      "Initial loss: 173.190\n",
      "Loss at step 000: 122.029\n",
      "Num =  3\n",
      "Final loss: 82.007\n",
      "0.9657757\n",
      "0.017273953\n",
      "Prediction loss: 183.191\n",
      "Initial loss: 171.345\n",
      "Loss at step 000: 118.848\n",
      "Num =  4\n",
      "Final loss: 83.364\n",
      "0.98278797\n",
      "0.006255584\n",
      "Prediction loss: 180.548\n",
      "Initial loss: 155.967\n",
      "Loss at step 000: 107.481\n",
      "Loss at step 020: 74.740\n",
      "Num =  5\n",
      "Final loss: 74.740\n",
      "0.9902169\n",
      "-0.0060361917\n",
      "Prediction loss: 133.872\n",
      "Initial loss: 165.887\n",
      "Loss at step 000: 113.235\n",
      "Loss at step 020: 76.406\n",
      "Num =  6\n",
      "Final loss: 76.396\n",
      "0.9986164\n",
      "-0.01695147\n",
      "Prediction loss: 157.743\n",
      "Initial loss: 149.853\n",
      "Loss at step 000: 106.168\n",
      "Loss at step 020: 73.529\n",
      "Num =  7\n",
      "Final loss: 73.529\n",
      "0.99273443\n",
      "-0.0045760833\n",
      "Prediction loss: 150.776\n",
      "Initial loss: 172.286\n",
      "Loss at step 000: 117.697\n",
      "Loss at step 020: 76.865\n",
      "Num =  8\n",
      "Final loss: 76.865\n",
      "0.99302274\n",
      "-0.012921641\n",
      "Prediction loss: 148.970\n",
      "Initial loss: 161.519\n",
      "Loss at step 000: 114.198\n",
      "Num =  9\n",
      "Final loss: 80.198\n",
      "0.98021156\n",
      "4.7000885e-05\n",
      "Prediction loss: 156.190\n",
      "Initial loss: 153.989\n",
      "Loss at step 000: 109.774\n",
      "Loss at step 020: 75.014\n",
      "Num =  10\n",
      "Final loss: 75.008\n",
      "0.9842539\n",
      "0.003880867\n",
      "Prediction loss: 180.287\n",
      "tf.Tensor(\n",
      "[[-0.31987622 -0.03840532 -1.1778575  ...  1.0631206   0.08310732\n",
      "   1.8899593 ]\n",
      " [-1.2885274   0.09213132  0.87635076 ... -0.05823033  0.32522798\n",
      "  -0.5311258 ]\n",
      " [ 0.95949507  0.5179837  -0.72239006 ... -1.2637936   0.00839469\n",
      "  -0.5856252 ]\n",
      " ...\n",
      " [-0.41905212  0.4794682  -0.5699573  ...  0.8520327   0.72084755\n",
      "   0.9864505 ]\n",
      " [ 0.84271723  1.0075938  -0.27336589 ...  0.53110915  1.4191827\n",
      "  -0.8398882 ]\n",
      " [ 1.295426    0.70815     1.15327    ... -0.00967527  0.81821513\n",
      "  -1.6311907 ]], shape=(100, 45), dtype=float32)\n",
      "Initial loss: 162.986\n",
      "Loss at step 000: 121.258\n",
      "Loss at step 020: 75.078\n",
      "Num =  1\n",
      "Final loss: 75.076\n",
      "0.9650429\n",
      "0.014810698\n",
      "Prediction loss: 98.213\n",
      "Initial loss: 154.932\n",
      "Loss at step 000: 118.030\n",
      "Loss at step 020: 73.805\n",
      "Num =  2\n",
      "Final loss: 73.803\n",
      "0.9975532\n",
      "0.013079668\n",
      "Prediction loss: 137.113\n",
      "Initial loss: 150.892\n",
      "Loss at step 000: 114.888\n",
      "Loss at step 020: 75.905\n",
      "Num =  3\n",
      "Final loss: 75.900\n",
      "0.9842068\n",
      "0.008187657\n",
      "Prediction loss: 113.632\n",
      "Initial loss: 157.658\n",
      "Loss at step 000: 117.135\n",
      "Loss at step 020: 77.347\n",
      "Num =  4\n",
      "Final loss: 77.343\n",
      "0.997597\n",
      "-0.011217378\n",
      "Prediction loss: 127.503\n",
      "Initial loss: 169.724\n",
      "Loss at step 000: 123.961\n",
      "Loss at step 020: 77.646\n",
      "Num =  5\n",
      "Final loss: 77.645\n",
      "0.99565905\n",
      "-0.013325595\n",
      "Prediction loss: 136.304\n",
      "Initial loss: 168.808\n",
      "Loss at step 000: 122.834\n",
      "Loss at step 020: 75.588\n",
      "Num =  6\n",
      "Final loss: 75.586\n",
      "0.9800379\n",
      "-0.006539347\n",
      "Prediction loss: 112.240\n",
      "Initial loss: 156.006\n",
      "Loss at step 000: 115.289\n",
      "Loss at step 020: 73.223\n",
      "Num =  7\n",
      "Final loss: 73.218\n",
      "0.9881756\n",
      "0.005131302\n",
      "Prediction loss: 110.697\n",
      "Initial loss: 158.493\n",
      "Loss at step 000: 118.215\n",
      "Loss at step 020: 78.209\n",
      "Num =  8\n",
      "Final loss: 78.164\n",
      "1.0056692\n",
      "-0.013009085\n",
      "Prediction loss: 110.275\n",
      "Initial loss: 146.921\n",
      "Loss at step 000: 110.137\n",
      "Loss at step 020: 74.069\n",
      "Num =  9\n",
      "Final loss: 74.065\n",
      "0.97191566\n",
      "0.010446746\n",
      "Prediction loss: 119.729\n",
      "Initial loss: 145.678\n",
      "Loss at step 000: 111.491\n",
      "Loss at step 020: 76.511\n",
      "Num =  10\n",
      "Final loss: 76.507\n",
      "0.9850269\n",
      "-0.0047879345\n",
      "Prediction loss: 114.617\n",
      "tf.Tensor(\n",
      "[[-0.92197824 -1.1881237  -0.68610156 ...  1.1346346  -1.0838406\n",
      "   1.0557364 ]\n",
      " [ 0.0843766  -0.48093462 -0.47701097 ... -1.7713866  -0.0230873\n",
      "  -1.3690802 ]\n",
      " [-0.28424114 -1.7868252  -2.059042   ...  0.03433969 -1.1419235\n",
      "  -1.5716556 ]\n",
      " ...\n",
      " [ 0.5330746  -1.7912259  -0.90404874 ... -0.4550726   0.3236183\n",
      "   0.44182885]\n",
      " [-0.7594677   0.4510199   0.12936619 ... -0.6941171   0.34369257\n",
      "  -1.7138333 ]\n",
      " [-0.03838942  0.5357406   0.45459062 ...  0.32020992 -0.32216632\n",
      "  -2.4881523 ]], shape=(100, 50), dtype=float32)\n",
      "Initial loss: 173.436\n",
      "Loss at step 000: 131.914\n",
      "Loss at step 020: 93.435\n",
      "Num =  1\n",
      "Final loss: 93.426\n",
      "0.9956842\n",
      "-0.019384887\n",
      "Prediction loss: 121.644\n",
      "Initial loss: 184.336\n",
      "Loss at step 000: 134.708\n",
      "Loss at step 020: 95.962\n",
      "Num =  2\n",
      "Final loss: 95.960\n",
      "1.01483\n",
      "0.007937607\n",
      "Prediction loss: 116.972\n",
      "Initial loss: 171.510\n",
      "Loss at step 000: 129.661\n",
      "Loss at step 020: 93.667\n",
      "Num =  3\n",
      "Final loss: 93.524\n",
      "0.9963535\n",
      "0.015003223\n",
      "Prediction loss: 131.483\n",
      "Initial loss: 195.182\n",
      "Loss at step 000: 142.424\n",
      "Loss at step 020: 97.669\n",
      "Num =  4\n",
      "Final loss: 97.661\n",
      "0.988125\n",
      "0.0061837477\n",
      "Prediction loss: 125.063\n",
      "Initial loss: 176.869\n",
      "Loss at step 000: 128.413\n",
      "Loss at step 020: 90.501\n",
      "Num =  5\n",
      "Final loss: 90.498\n",
      "0.9939592\n",
      "0.018580366\n",
      "Prediction loss: 131.940\n",
      "Initial loss: 163.587\n",
      "Loss at step 000: 125.863\n",
      "Loss at step 020: 95.296\n",
      "Num =  6\n",
      "Final loss: 95.285\n",
      "0.9955421\n",
      "-0.018623617\n",
      "Prediction loss: 141.201\n",
      "Initial loss: 172.096\n",
      "Loss at step 000: 130.508\n",
      "Loss at step 020: 95.403\n",
      "Num =  7\n",
      "Final loss: 95.399\n",
      "0.99736154\n",
      "-0.03191954\n",
      "Prediction loss: 143.298\n",
      "Initial loss: 190.048\n",
      "Loss at step 000: 136.237\n",
      "Loss at step 020: 91.294\n",
      "Num =  8\n",
      "Final loss: 91.289\n",
      "0.9967642\n",
      "0.015047009\n",
      "Prediction loss: 164.566\n",
      "Initial loss: 196.201\n",
      "Loss at step 000: 139.322\n",
      "Loss at step 020: 87.651\n",
      "Num =  9\n",
      "Final loss: 87.536\n",
      "1.0196849\n",
      "-0.0032431923\n",
      "Prediction loss: 146.994\n",
      "Initial loss: 164.386\n",
      "Loss at step 000: 121.455\n",
      "Loss at step 020: 86.268\n",
      "Num =  10\n",
      "Final loss: 86.263\n",
      "0.9963847\n",
      "-0.008987255\n",
      "Prediction loss: 113.380\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EXAMPLES = 100 # d\n",
    "NUM_SET = 10 # n\n",
    "LOG = False\n",
    "\n",
    "k_val = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "k_val2 = [2, 3, 5, 7, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "k_val3=[100]\n",
    "\n",
    "function = tf.nn.relu\n",
    "func_id = \"ReLU\"\n",
    "\n",
    "#Quad 0.0005 Relu 0.0001\n",
    "\n",
    "\n",
    "learning_rate = 0.5\n",
    "min_stop = 0.001\n",
    "\n",
    "\n",
    "# Training description\n",
    "\n",
    "def description():\n",
    "    return 'd=' + str(NUM_EXAMPLES)+ '_n=' + str(NUM_SET) + '_with_' + func_id +'_activation_0.0005'\n",
    "\n",
    "# Create directory\n",
    "\n",
    "#pathlib.Path('/' + description()).mkdir(parents=True, exist_ok=True)\n",
    "try:\n",
    "    original_umask = os.umask(0)\n",
    "    os.makedirs(description())\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# Methods defined\n",
    "\n",
    "decay_weight = 0.1\n",
    "def prediction(input, weight, bias):\n",
    "    return activation(tf.matmul(input, weight) + bias)\n",
    "\n",
    "def activation(input):\n",
    "    return function(input)\n",
    "\n",
    "def loss(weights, biases):\n",
    "    error = prediction(training_inputs, weights, biases) - training_outputs# + decay_rate * W ** 2\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(weights, biases):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(weights, biases)\n",
    "    return tape.gradient(loss_value, [weights, biases])\n",
    "\n",
    "def pred_loss(weights, biases):\n",
    "    error = prediction_outputs - prediction(prediction_inputs, weights, biases)\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "\n",
    "loss_t = []\n",
    "pred_t = []\n",
    "\n",
    "\n",
    "\n",
    "for NUM_K in k_val2:\n",
    "    num = 0\n",
    "    losses_tot = []\n",
    "    \n",
    "    # Training Weight initialization\n",
    "\n",
    "\n",
    "    training_inputs = tf.random_normal([NUM_SET, NUM_EXAMPLES])\n",
    "    noise = tf.random_normal([NUM_SET, NUM_K])\n",
    "    training_weights = tf.random_normal([NUM_EXAMPLES, NUM_K])\n",
    "    print(training_weights)\n",
    "    training_outputs = tf.matmul(training_inputs, training_weights) + noise\n",
    "\n",
    "    pred_num = 1\n",
    "\n",
    "    prediction_inputs = tf.random_normal([pred_num, NUM_EXAMPLES])\n",
    "    prediction_outputs = tf.matmul(prediction_inputs, training_weights)\n",
    "\n",
    "    file_name = description() + 'k=' + str(NUM_K) + '.xlsx'\n",
    "    directory = description() + '/' + file_name\n",
    "\n",
    "    xfile = openpyxl.Workbook()\n",
    "\n",
    "\n",
    "    sh = xfile.create_sheet('Mean and std')\n",
    "    sh[\"A1\"] = \"Mean\"\n",
    "    sh[\"B1\"] = \"STD\"\n",
    "    sh[\"A2\"] = tf.reduce_mean(training_weights).numpy()\n",
    "    sh[\"B2\"] = np.std(training_weights.numpy())\n",
    "\n",
    "    xfile.save(directory)\n",
    "\n",
    "\n",
    "    \n",
    "    # Training Stage\n",
    "\n",
    "    sheet = xfile.create_sheet('k=' + str(NUM_K) + ' d=' + str(NUM_EXAMPLES)+ ' n=' + str(NUM_SET))\n",
    "    avg = []\n",
    "    avg2 = []\n",
    "    \n",
    "    for it in range(10):\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #workbook = xlsxwriter.Workbook('Eager_data.xlsx')\n",
    "        #worksheet = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "        Weights = []\n",
    "        Biases = []\n",
    "\n",
    "        train_steps = 4000\n",
    "\n",
    "        #Relu rate is 0.005  Quadratic is 0.0002 for small n\n",
    "        #Relu rate is 0.5 Large sample n=1000\n",
    "        #Qua rate is 0.002 Large sample n=1000\n",
    "\n",
    "        W = tfe.Variable(tf.random_normal([NUM_EXAMPLES, NUM_K]))\n",
    "        B = tfe.Variable(tf.random_normal([NUM_SET, NUM_K]))\n",
    "        print(\"Initial loss: {:.3f}\".format(loss(W, B)))\n",
    "\n",
    "        previous = 0\n",
    "        losses = []\n",
    "        step = train_steps\n",
    "\n",
    "        for i in range(train_steps):\n",
    "            dW, dB = grad(W, B)\n",
    "            W.assign_sub(dW * learning_rate)\n",
    "            B.assign_sub(dB * learning_rate)\n",
    "            loss_val = loss(W, B)\n",
    "            losses.append(loss_val)\n",
    "            if i % 20 == 0:\n",
    "                if tf.is_nan(loss_val):\n",
    "                    break\n",
    "                print(\"Loss at step {:03d}: {:.3f}\".format(i, loss_val))\n",
    "            if abs(previous - loss_val) < min_stop:\n",
    "                previous = loss_val\n",
    "                step = i\n",
    "                break\n",
    "            else:\n",
    "                previous = loss_val\n",
    "\n",
    "        #worksheet.write_row(num, 0, [previous])\n",
    "\n",
    "        num += 1\n",
    "        print(\"Num = \", num)\n",
    "        Weights.append(W)\n",
    "        Biases.append(B)\n",
    "\n",
    "        print(\"Final loss: {:.3f}\".format(loss(W, B)))\n",
    "        print(np.std(W.numpy()))\n",
    "        print(tf.reduce_mean(W).numpy())\n",
    "        #print(\"W = {}, B = {}\".format(W.numpy(), B.numpy()))\n",
    "\n",
    "\n",
    "        sheet['A1'] = \"Num\"\n",
    "        sheet['A' + str(num + 1)] = num\n",
    "        sheet['B1'] = \"Loss\"\n",
    "        sheet['B' + str(num + 1)] = previous.numpy()\n",
    "        sheet['C1'] = \"Mean\"\n",
    "        sheet['C' + str(num + 1)] = tf.reduce_mean(W).numpy()\n",
    "        sheet['D1'] = \"Std\"\n",
    "        sheet['D' + str(num + 1)] = np.std(W.numpy())\n",
    "        sheet['E1'] = \"Steps\"\n",
    "        sheet['E' + str(num + 1)] = np.std(W.numpy())\n",
    "\n",
    "        avg.append(previous.numpy())\n",
    "\n",
    "        xfile.save(directory)\n",
    "\n",
    "        losses_tot.append(losses)\n",
    "\n",
    "        pred_loss_val = pred_loss(W, B)  \n",
    "\n",
    "        print('Prediction loss: {:.3f}'.format(pred_loss_val))\n",
    "\n",
    "        sheet['F1'] = \"Prediction loss\"\n",
    "        sheet['F' + str(num + 1)] = pred_loss_val.numpy()\n",
    "        avg2.append(pred_loss_val.numpy())\n",
    "\n",
    "    loss_t.append(np.mean(avg))\n",
    "    pred_t.append(np.mean(avg2))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('step')\n",
    "    if LOG:\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "    for l in losses_tot:\n",
    "        plt.plot(l)\n",
    "    plt.savefig(directory + '.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "plt.plot(k_val2, np.divide(loss_t, pred_t))\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Predicted/Training\")\n",
    "plt.savefig(\"Graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('step')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "for l in losses_tot:\n",
    "    plt.plot(l)\n",
    "\n",
    "plt.savefig(str('Fig k=' + str(NUM_K) + ' n=' + str(NUM_EXAMPLES)+ func_id + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_k",
   "language": "python",
   "name": "project_k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
